#-------------------------------------------------------------
# IBM Confidential
# OCO Source Materials
# (C) Copyright IBM Corp. 2010, 2014
# The source code for this program is not published or
# otherwise divested of its trade secrets, irrespective of
# what has been deposited with the U.S. Copyright Office.
#-------------------------------------------------------------

# Implements multiclass C-SVM with squared slack variables
#
# Example Usage:
# Assume L2SVM_HOME is set to the home of the dml script
# Assume input and output directories are on hdfs as INPUT_DIR and OUTPUT_DIR
# Assume epsilon = 0.001, lambda = 1, maxiterations = 100
#
# hadoop jar SystemML.jar -f $L2SVM_HOME/l2-svm.dml -nvargs X=$INPUT_DIR/X 
#  	     		     			    	    				Y=$INPUT_DIR/Y 
#							    							icpt=0 
# 	  						    							tol=0.001 
#							    							reg=1 
#							    							maxiter=100 
#							    							model=$OUPUT_DIR/w
#
# Note about inputs: 
# Assumes that labels (entries in Y) are set to either -1 or +1

$icpt=0
$tol=0.001
$reg=1.0
$maxiter=100

X = read($X)
Y = read($Y)

check_min = min(Y)
check_max = max(Y)
num_min = sum(ppred(Y, check_min, "=="))
num_max = sum(ppred(Y, check_max, "=="))
if(num_min + num_max != nrow(Y)) print("please check Y, it should contain only 2 labels")
else{
	if(check_min != -1 | check_max != +1) 
		Y = 2/(check_max - check_min)*Y - (check_min + check_max)/(check_max - check_min)
}

intercept = $icpt
epsilon = $tol
lambda = $reg
maxiterations = $maxiter

num_samples = nrow(X)
dimensions = ncol(X)

#checking Y's correctness
max_y = max(Y)
min_y = min(Y)
sum_abs_y = sum(abs(Y))

if(max_y == 1 & min_y == -1 & sum_abs_y == num_samples){
  if (intercept == 1) {
    ones  = matrix(1, rows=num_samples, cols=1)
    X = append(X, ones);
  }

  num_rows_in_w = dimensions
  if(intercept == 1){
    num_rows_in_w = num_rows_in_w + 1
  }
  w = matrix(0, rows=num_rows_in_w, cols=1)

  g_old = t(X) %*% Y
  s = g_old

  iter = 0
  continue = 1
  while(continue == 1 & iter < maxiterations)  {
    # minimizing primal obj along direction s
    step_sz = 0
    Xd = X %*% s
    wd = lambda * sum(w * s)
    dd = lambda * sum(s * s)
    continue1 = 1
    while(continue1 == 1){
      tmp_w = w + step_sz*s
      out = 1 - Y * (X %*% tmp_w)
      sv = ppred(out, 0, ">")
      out = out * sv
      g = wd + step_sz*dd - sum(out * Y * Xd)
      h = dd + sum(Xd * sv * Xd)
      step_sz = step_sz - g/h
      if (g*g/h < 0.0000000001){
        continue1 = 0
      }
    }

    #update weights
    w = w + step_sz*s

    out = 1 - Y * (X %*% w)
    sv = ppred(out, 0, ">")
    out = sv * out
    obj = 0.5 * sum(out * out) + lambda/2 * sum(w * w)
    g_new = t(X) %*% (out * Y) - lambda * w

    print("ITER " + iter + ": OBJ=" + obj)
	
    tmp = sum(s * g_old)
    if(step_sz*tmp < epsilon*obj){
      continue = 0
    }

    #non-linear CG step
    be = sum(g_new * g_new)/sum(g_old * g_old)
    s = be * s + g_new
    g_old = g_new

    iter = iter + 1
  }

  write(w, $model, format="text")
}else{
  print("Training labels (Y) can only be -1 or +1 (binary classification). "
  	+ "Please ensure that before invoking L2SVM.dml");
}
