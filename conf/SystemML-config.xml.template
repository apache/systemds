<!--
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 * 
 *   http://www.apache.org/licenses/LICENSE-2.0
 * 
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
-->

<root>
   <!-- local fs tmp working directory-->
   <sysml.localtmpdir>/tmp/systemml</sysml.localtmpdir>

   <!-- hdfs tmp working directory--> 
   <sysml.scratch>scratch_space</sysml.scratch> 

   <!-- compiler optimization level, valid values: 0 | 1 | 2 | 3 | 4, default: 2 -->
   <sysml.optlevel>2</sysml.optlevel>  

   <!-- default number of reduce tasks per MR job, default: 2 x number of nodes -->
   <sysml.numreducers>10</sysml.numreducers> 
   
   <!-- override jvm reuse flag for specific MR jobs, valid values: true | false  -->
   <sysml.jvmreuse>false</sysml.jvmreuse> 

   <!-- default block dim for binary block files -->
   <sysml.defaultblocksize>1000</sysml.defaultblocksize> 

   <!-- run systemml control program as yarn appmaster, in case of MR1 always falls back to client, please disable for debug mode -->
   <sysml.yarn.appmaster>false</sysml.yarn.appmaster>

   <!-- maximum jvm heap size of the dml yarn appmaster in MB, the requested memory is 1.5x this parameter -->
   <sysml.yarn.appmaster.mem>2048</sysml.yarn.appmaster.mem>

   <!-- maximum jvm heap size of the map/reduce tasks in MB, the requested memory is 1.5x this parameter, negative values ignored  -->
   <sysml.yarn.mapreduce.mem>2048</sysml.yarn.mapreduce.mem>

   <!-- yarn application submission queue, relevant for default capacity scheduler -->
   <sysml.yarn.app.queue>default</sysml.yarn.app.queue>
   
   <!-- enables multi-threaded operations in singlenode control program -->
   <sysml.cp.parallel.ops>true</sysml.cp.parallel.ops>
   
   <!-- enables multi-threaded read/write in singlenode control program -->
   <sysml.cp.parallel.io>true</sysml.cp.parallel.io>
   
   <!-- enables compressed linear algebra, experimental feature -->
   <sysml.compressed.linalg>auto</sysml.compressed.linalg>
   
   <!-- enables operator fusion via code generation, experimental feature -->
   <sysml.codegen.enabled>false</sysml.codegen.enabled>
   
   <!-- set the codegen java compiler (auto, janino, javac) -->
   <sysml.codegen.compiler>auto</sysml.codegen.compiler>

   <!-- set the codegen optimizer (fuse_all, fuse_no_redundancy, fuse_cost_based_v2) -->
   <sysml.codegen.compiler>fuse_cost_based_v2</sysml.codegen.compiler>
   
   <!-- if codegen.enabled, enables source code caching of fused operators -->
   <sysml.codegen.plancache>true</sysml.codegen.plancache>
   
   <!-- if codegen.enabled, compile literals as constants: 1..heuristic, 2..always -->
   <sysml.codegen.literals>1</sysml.codegen.literals>
   
   <!-- enables native blas for matrix multiplication and convolution, experimental feature (options: auto, mkl, openblas, none) -->
   <sysml.native.blas>none</sysml.native.blas>

   <!-- prints finegrained statistics information -->
   <sysml.stats.finegrained>false</sysml.stats.finegrained>
   
   <!-- prints extra statistics information for GPU -->
   <sysml.stats.extraGPU>false</sysml.stats.extraGPU>

   <!-- prints extra statistics information for Deep Neural Networks done in CP mode -->
   <sysml.stats.extraDNN>false</sysml.stats.extraDNN>

    <!-- sets the GPUs to use per process, -1 for all GPUs, a specific GPU number (5), a range (eg: 0-2) or a comma separated list (eg: 0,2,4)-->
    <sysml.gpu.availableGPUs>-1</sysml.gpu.availableGPUs>
    
    <!-- whether to synchronize GPUs after every GPU instruction -->
    <sysml.gpu.sync.postProcess>true</sysml.gpu.sync.postProcess>
    
    <!-- whether to perform eager CUDA free on rmvar instruction -->
    <sysml.gpu.eager.cudaFree>false</sysml.gpu.eager.cudaFree>
   
   <!-- maximum wrap length for instruction and miscellaneous timer column of statistics -->
   <sysml.stats.maxWrapLength>30</sysml.stats.maxWrapLength>
</root>
