#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
#-------------------------------------------------------------

# In The bandit function the objective is to find an arm that optimises a known functional of the unknown arm-reward distributions.
#
# INPUT PARAMETERS:
# ----------------------------------------------------------------------------------------------------------------------
# NAME              TYPE               DEFAULT            MEANING
# ----------------------------------------------------------------------------------------------------------------------
# X_train           Matrix[Double]     ---
# Y_train           Matrix[Double]     ---
# X_test            Matrix[Double]     ---
# Y_test            Matrix[Double]     ---
# metaList          List[Unknown]      ---
# evaluationFunc    String             ---
# evalFunHp         Matrix[Double]     ---
# lp                Frame[Unknown]     ---
# primitives        Frame[Unknown]     ---
# params            Frame[Unknown]     ---
# K                 Integer            3
# R                 Integer            50
# baseLineScore     Double
# cv                Boolean
# cvk               Integer            2
# verbose           Boolean            TRUE
# output            String             ""
# ----------------------------------------------------------------------------------------------------------------------
#
# OUTPUT:
# ----------------------------------------------------------------------------------------------------------------------
# NAME      TYPE             MEANING
# ----------------------------------------------------------------------------------------------------------------------
# perf      Boolean
# ----------------------------------------------------------------------------------------------------------------------

m_bandit = function(Matrix[Double] X_train, Matrix[Double] Y_train, Matrix[Double] X_test, Matrix[Double] Y_test, List[Unknown] metaList,
  String evaluationFunc, Matrix[Double] evalFunHp, Frame[Unknown] lp, Frame[Unknown] primitives, Frame[Unknown] param, Integer k = 3,
  Integer R=50, Double baseLineScore, Boolean cv,  Integer cvk = 2, Double ref = 0, Boolean enablePruning = FALSE, Boolean verbose = TRUE, String output="")
  return(Boolean perf)
  # return (Frame[Unknown] bestPipeline, Matrix[Double] bestHyperparams, Matrix[Double] bestAccuracy, Frame[String] feaFrameOuter) 
{
  print("Starting optimizer")
  totalPruneCount = 0
  FLAG_VARIABLE = 5
  pipelines_executed = 0
  HYPERPARAM_LENGTH = (ncol(lp) * FLAG_VARIABLE * 3) + 1 ## num of col in logical * 5 meat flag vars * max hyperparam per op + 1 accuracy col
  bestPipeline = frame("", rows=1, cols=1)
  bestHyperparams = as.matrix(0)
  bestAccuracy = as.matrix(0)
  # initialize bandit variables
  # variable names follow publication where algorithm is introduced
  eta = 2  # the halving ratio is fixed to 2
  s_max = floor(log(R,eta)) - 1;
  # initialize output variables
  hparam = matrix(0, rows=k*(s_max+1), cols=HYPERPARAM_LENGTH)
  pipeline = frame(0, rows=k*(s_max+1), cols=ncol(lp)+1)
  endIdx = matrix(k, rows=(s_max+1), cols=1)
  endIdx = cumsum(endIdx)
  startIdx = (endIdx - k) + 1

  n = ifelse(s_max >= nrow(lp), nrow(lp), n = ceil(nrow(lp)/(s_max + 1));)
    
  for(s in s_max:0, check=0) { # TODO convert to parfor
    
   # result variables
    bracket_hp = matrix(0, rows=k*(s+1)+k, cols=HYPERPARAM_LENGTH)
    bracket_pipel = matrix(0, rows=k*(s+1)+k, cols=3)
    start=1; end=0;
    
    # # compute the number of initial pipelines n
    r = R * eta^(-s);
    configurations = lp[1:(min(n, nrow(lp)))]
    # append configuration keys for extracting the pipeline later on
    id = seq(1, nrow(configurations))
    configurations = cbind(as.frame(id), configurations)
    # save the original configuration as a lookup table
    lookup = configurations

    for(i in 0:s) {
      # successive halving
      n_i = min(max(as.integer(floor(n * eta^(-i))), 1), nrow(configurations));
      r_i = as.integer(floor(r * eta^i));
      
      if(verbose) {
        print("no of configurations ---------"+n_i)
        print("no of resources --------------"+r_i)
        print("iteration  ---------------------"+i+" out of "+s)
      }
      configurations = configurations[1:n_i, ]
      pipelines_executed = pipelines_executed + (n_i * r_i)
      [outPip,outHp, pruneCount] = run_with_hyperparam(ph_pip=configurations, r_i=r_i, X=X_train, Y=Y_train, Xtest=X_test, Ytest=Y_test, metaList=metaList,
        evaluationFunc=evaluationFunc, evalFunHp=evalFunHp, param=param, cv=cv, cvk=cvk, ref=ref, enablePruning=enablePruning)
      totalPruneCount = totalPruneCount + pruneCount
      # sort the pipelines by order of accuracy decreasing
      a = order(target = outPip, by = 1, decreasing=TRUE, index.return=FALSE)
      b = order(target = outHp, by = 1, decreasing=TRUE, index.return=FALSE)
      rowIndex = min(k, nrow(a))

      # maintain the brackets results
      end = end + rowIndex
      bracket_pipel[start:end, 1:ncol(a)] =  a[1:rowIndex,]
      bracket_hp[start:end, 1:ncol(b)] =  b[1:rowIndex,]
      start = end + 1

      # sort the configurations for successive halving
      avergae_perf =  getMaxPerConf(outPip, nrow(configurations)) 
      sortMask = matrix(1, rows=1, cols=ncol(configurations))
      configurations = frameSort(cbind(avergae_perf, configurations), cbind(as.matrix(0), sortMask), TRUE)
      configurations = configurations[, 2:ncol(configurations)]
    }
    if(n < nrow(lp))
      lp = lp[n+1:nrow(lp),]
    bracket_pipel = removeEmpty(target=bracket_pipel, margin="rows")
    bracket_hp = removeEmpty(target=bracket_hp, margin="rows")
    # keep the best k results for each bracket
    [bracket_bestPipeline, bracket_bestHyperparams] = extractBracketWinners(bracket_pipel, bracket_hp, k, lookup)
    # optimize by the features
    startOut = as.scalar(startIdx[s+1])
    endOut = min(as.scalar(endIdx[s+1]), (startOut + nrow(bracket_bestPipeline) - 1))
    pipeline[startOut:endOut, ] = bracket_bestPipeline
    hparam[startOut:endOut, 1:ncol(bracket_bestHyperparams)] = bracket_bestHyperparams
  }
  [bestPipeline, bestHyperparams] = extractTopK(pipeline, hparam, baseLineScore, k)
  bestAccuracy = as.matrix(bestPipeline[,1])
  bestHyperparams = bestHyperparams[,2:ncol(bestHyperparams)]
  bestPipeline = bestPipeline[, 2:ncol(bestPipeline)]
  imp = as.double(as.scalar(bestAccuracy[1, 1])) - as.double(baseLineScore)
  perf = imp > 0
  applyFunc = bestPipeline
  for(k in 1:nrow(bestPipeline))
  {
    bestPip = removeEmpty(target=bestPipeline[k], margin="cols")
    applyOp = getParamMeta(bestPip, param)
    applyFunc[k, 1:ncol(applyOp)] = applyOp
  }
  if(verbose) {
    print("dirty accuracy "+toString(baseLineScore))  
    print("topk pipelines \n"+toString(bestPipeline))
    print("topk hyper params \n"+toString(bestHyperparams))
    print("topk  scores: \n"+toString(bestAccuracy))
    print("evalHp: \n"+toString(evalFunHp))
    print("performance improvement "+ imp)
    print("total physical pipelines to be executed: "+pipelines_executed)
    print("prune count: "+totalPruneCount)
    print("actual executed pipelines: "+(pipelines_executed - totalPruneCount))
  }
  write(bestPipeline, output+"/pip.csv", format="csv")
  write(bestHyperparams, output+"/hp.csv", format="csv")
  write(bestAccuracy, output+"/bestAcc.csv", format="csv")
  write(baseLineScore, output+"/dirtyScore.csv", format="csv")
  write(evalFunHp, output+"/evalHp.csv", format="csv")
  write(applyFunc, output+"/applyFunc.csv", format="csv")
}

# this method will extract the physical pipelines for a given logical pipelines
get_physical_configurations = function(Frame[String] logical, Scalar[int] numConfigs = 10, 
  Frame[Unknown] primitives)
  return(Frame[String] physical)
{
  # load the primitives
  physical = as.frame("NaN")
  ed = primitives[, 1]
  mvi = primitives[, 2]
  outliers = primitives[,3]
  ec = primitives[, 4]
  scale = primitives[, 5]
  ci = primitives[, 6]
  dummy = primitives[,7]
  dim = primitives[, 8]
 
  operator = frame(0, rows=nrow(primitives), cols=ncol(logical))  # combine all logical primitives
  parfor(j in 1:ncol(logical), check = 0)
  {
    # extract the physical primitives
    if(as.scalar(logical[1,j]) == "ED")
      operator[, j] = ed;
    else if(as.scalar(logical[1,j]) == "EC")
      operator[, j] = ec;  
    else if(as.scalar(logical[1,j]) == "OTLR")
      operator[, j] = outliers;
    else if(as.scalar(logical[1,j]) == "MVI")
      operator[, j] = mvi;
    else if(as.scalar(logical[1,j]) == "CI")
      operator[, j] = ci;
    else if(as.scalar(logical[1,j]) == "DIM")
      operator[, j] =  dim;
    else if(as.scalar(logical[1,j]) == "DUMMY") 
      operator[, j] =  dummy; 
    else if(as.scalar(logical[1,j]) == "SCALE")
      operator[, j] = scale;
    else print("invalid operation "+as.scalar(logical[1,j]))
  }
  physical = operator 
}

# this method will call the execute pipelines with their hyper-parameters
run_with_hyperparam = function(Frame[Unknown] ph_pip, Integer r_i, Matrix[Double] X, Matrix[Double] Y,
  Matrix[Double] Xtest, Matrix[Double] Ytest, List[Unknown] metaList, String evaluationFunc, Matrix[Double] evalFunHp,
  Frame[Unknown] param, Boolean cv,  Integer cvk = 2, Double ref = 0, Boolean enablePruning = FALSE, Boolean default = FALSE)
  return (Matrix[Double] output_operator, Matrix[Double] output_hyperparam, Integer pruneCount, Matrix[Double] changesByPipMatrix)
{
  changesByPipMatrix = matrix(0, rows=nrow(ph_pip) * r_i, cols=1)
  pruneCount = 0
  output_hp = matrix(0, nrow(ph_pip)*r_i, (ncol(ph_pip)-1) * 5 * 3)
  output_accuracy = matrix(0, nrow(ph_pip)*r_i, 1)
  output_pipelines = matrix(0, nrow(ph_pip)*r_i, 2)
  # rows in validation set
  clone_X = X
  clone_Y = Y
  clone_Xtest = Xtest
  clone_Ytest = Ytest
  index = 1
  id = as.matrix(ph_pip[, 1])
  ph_pip = ph_pip[, 2:ncol(ph_pip)]
  evalFunOutput = as.matrix(0)

  for(i in 1:nrow(ph_pip))
  {
    # execute configurations with r resources
    op = removeEmpty(target=ph_pip[i], margin="cols")
    print("PIPELINE EXECUTION START ... "+toString(op))
    [hp, applyFunctions, no_of_res, no_of_flag_vars] = getHyperparam(op, param, r_i, default, enablePruning)
    pip_toString = pipToString(op)
    hpForPruning = matrix(0, rows=1, cols=ncol(op))
    changesByOp = matrix(0, rows=1, cols=ncol(op))
    metaList["applyFunc"] = applyFunctions
    for(r in 1:no_of_res)
    {
      # as the matrix first block of r rows belongs to first operator and r+1 block of rows to second operator 
      # we need to extract a row from each block
      indexes = matrix(no_of_res, rows=ncol(op), cols=1)
      indexes[1, 1] = r
      indexes = cumsum(indexes)
      indexes = table(indexes, 1, 1, nrow(hp), 1)
      hp_matrix = removeEmpty(target = hp, margin="rows", select = indexes)
      # # check if the pruning could be applied to avoid unnecessary executions
      pruneSignal = pruningSignal(op, hp_matrix, hpForPruning, changesByOp)
      executionSingnal = ifelse(enablePruning, pruneSignal, TRUE)
      ref = ifelse(enablePruning, ref, 0)
      if(executionSingnal)
      {
        t1 = time()
        if(cv)
        {
          pipList = list(ph = op, hp = hp_matrix, flags = no_of_flag_vars)
          [accuracy, evalHp, hpForPruning, changesByOp, changesByPip] = crossV(X=X, y=Y, cvk=cvk, evalFunHp=evalFunHp,
            pipList=pipList, metaList=metaList, hpForPruning=hpForPruning, 
          changesByOp=changesByOp, evalFunc=evaluationFunc, ref=ref)
        }
        else 
        {
          [eXtrain, eYtrain, eXtest, eYtest, Tr, hpForPruning, changesByOp, changesByPip] = executePipeline(pipeline=op, 
            Xtrain=X, Ytrain=Y, Xtest=Xtest, Ytest=Ytest, metaList=metaList,  hyperParameters=hp_matrix, hpForPruning=hpForPruning,
            changesByOp=changesByOp, flagsCount=no_of_flag_vars, test=TRUE, verbose=FALSE)
          if(max(eYtrain) == min(eYtrain)) 
            print("Y contains only one class")
          else if(changesByPip < ref)
            print("prunning alert 2: no training the model due to minimum changes")
          else 
            evalFunOutput = eval(evaluationFunc, list(X=eXtrain, Y=eYtrain, Xtest=eXtest, Ytest=eYtest, Xorig=as.matrix(0), evalFunHp=evalFunHp))
            accuracy = as.scalar(evalFunOutput[1, 1])
        }

        # evalFunOutput = eval(evaluationFunc, argList)  
        accT = floor((time() - t1) / 1e+6)  
        matrix_width = as.matrix(nrow(hp_matrix) * ncol(hp_matrix))
        hp_vec = cbind(matrix_width, matrix(hp_matrix, rows=1, cols=nrow(hp_matrix)*ncol(hp_matrix), byrow=TRUE))
        output_accuracy[index, 1] = accuracy
        output_hp[index, 1:ncol(hp_vec)] = hp_vec
        output_pipelines[index, ] = cbind(as.matrix(index), id[i,1])
        X = clone_X
        Y = clone_Y
        Xtest = clone_Xtest
        Ytest = clone_Ytest
      }
      else
      {
        pruneCount = pruneCount + 1
        print("prunningAlert: not executing instance : "+r+" pruneCount"+pruneCount)
      }
      changesByPipMatrix[index] = changesByPip
      index = index + 1
    }
    X = clone_X
    Y = clone_Y
    Xtest = clone_Xtest
    Ytest = clone_Ytest
  }
  output_hyperparam = removeEmpty(target=cbind(output_accuracy, output_hp), margin="rows")
  output_operator = removeEmpty(target=cbind(output_accuracy, output_pipelines), margin="rows")
}

# extract the hyper-parameters for pipelines
getHyperparam = function(Frame[Unknown] pipeline, Frame[Unknown]  hpList, Integer no_of_res, Boolean default, Boolean enablePruning)
  return (Matrix[Double] paramMatrix, Frame[Unknown] applyFunc, Integer no_of_res, Integer NUM_META_FLAGS)
{

  allParam = 0;
  NUM_META_FLAGS = 5
  NUM_DEFAULT_VALUES = 4

  # load the hyper-parameters values
  paramList = list()
  # store the row indexes of the operator matches
  [applyFunc, indexes, paramCount] = getParamMeta(pipeline, hpList)

  hpList = hpList[, 3:ncol(hpList)]
  DEFAULT_INDEX = 7
  START_INDEX = 11 # value from where the hyper-params starts after skipping meta flags

  # if there are no hyper-parameters than change the values of resources
  # so that the pipeline is only executed once and no resource are wasted, saving looping
  no_of_res = ifelse(sum(paramCount) > 0, no_of_res, 1)
  # the below matrix stores the different combinations of hyper-parameter value for each pipeline
  # if the resource value is greater than zero this means for 1 pipeline it will store r rows where each row store set
  # of hyperparameter values for ith pipeline. If resource value rv = 10 and ncol(pip) = 3 then the output matrix will have
  # 10*3= 30 rows and 1:10 hyper-paramters for i-the pipeline 11:20 for (i+1)-th pipeline and so on
  # this matrix stores no. of hps, values of hps, and flags
  paramMatrix = matrix(0, rows=ncol(pipeline)*no_of_res, cols=max(paramCount)+NUM_META_FLAGS+1)

  for(i in 1:ncol(pipeline)) {
    op = as.scalar(pipeline[1, i])
    index = as.scalar(indexes[i])
    no_of_param = as.integer(as.scalar(paramCount[i]))
    # extract hasY and verbose flags
    attachMask = matrix(as.scalar(hpList[index, 2]), rows=no_of_res, cols=1)
    attachFD = matrix(as.scalar(hpList[index, 3]), rows=no_of_res, cols=1)
    attachY = matrix(as.scalar(hpList[index, 4]), rows=no_of_res, cols=1)
    isVerbose = matrix(as.scalar(hpList[index, 5]), rows=no_of_res, cols=1)
    dataFlag = matrix(as.scalar(hpList[index, 6]), rows=no_of_res, cols=1)
    if(no_of_param > 0) {
      paramIdx = START_INDEX
      typeIdx = START_INDEX
      OpParam = matrix(0, rows=no_of_res, cols=max(paramCount))
      if(default) {
        OpParam[1, 1:no_of_param] = as.matrix(hpList[index, DEFAULT_INDEX:DEFAULT_INDEX+(no_of_param - 1)])
      }
      else {
        for(j in 1:no_of_param) {
          type = as.scalar(hpList[index, typeIdx])
          paramValIndex = (no_of_param) + paramIdx
          minVal =  as.scalar(hpList[index, paramValIndex])
          maxVal = as.scalar(hpList[index, paramValIndex + 1])
          if(type == "FP") {
            val = rand(rows=no_of_res, cols=1, min=minVal, max=maxVal, pdf="uniform");
            OpParam[, j] = val;
          }
          else if(type == "INT") {
            if(as.integer(maxVal) > no_of_res)
              val = sample(as.integer(maxVal), no_of_res, FALSE)
            else 
              val = sample(as.integer(maxVal), no_of_res, TRUE)
            less_than_min = val < as.integer(minVal);
            val = (less_than_min * minVal) + val;
            OpParam[, j] = val;
          }
          else if(type == "BOOL") {
            if(maxVal == 1) {
              s = sample(2, no_of_res, TRUE);
              b = s - 1;
              OpParam[, j] = b;
            } 
            else
              OpParam[, j] = matrix(0, rows=no_of_res, cols=1)
          }
          else
            print("invalid data type")  # TODO handle string set something like {,,}
          
          paramIdx = paramIdx + 2
          typeIdx = typeIdx + 1
        }
      }
      if((op == "outlierBySd" | op == "outlierByIQR" | op == "imputeByFd") & no_of_res > 1 & enablePruning) 
        OpParam = order(target=OpParam, by = 1, decreasing = FALSE, index.return = FALSE)
      # hyper-parameter vector contains no. of hp, values of hp, and flag values
      OpParam = cbind(matrix(no_of_param, rows=nrow(OpParam), cols=1),OpParam, attachMask,
        attachFD, attachY, isVerbose, dataFlag)
    }
    else {
      # no hyper-parameters, so create a dummy matrix of zeros so flags are always aligned
      dummy = matrix(0, rows=no_of_res, cols=max(paramCount)+1)
      OpParam = cbind(dummy, attachMask, attachFD, attachY)
      OpParam = cbind(OpParam, isVerbose, dataFlag)
    }
    paramMatrix[((i-1)*no_of_res)+1:i*no_of_res, 1:ncol(OpParam)] = OpParam
  }
}


# extract the top k pipelines as a final result after deduplication and sorting
extractTopK = function(Frame[Unknown] pipeline, Matrix[Double] hyperparam, 
  Double baseLineScore, Integer k)
  return (Frame[Unknown] bestPipeline, Matrix[Double] bestHyperparams)
{
  hyperparam = order(target = hyperparam, by = 1, decreasing=TRUE, index.return=FALSE)
  pipeline = frameSort(pipeline, cbind(as.matrix(0), matrix(1, rows=1, cols=ncol(pipeline) - 1)), TRUE)
  # remove the row with accuracy less than test accuracy 
  mask = (hyperparam[, 1] < baseLineScore) == 0
  hyperparam = removeEmpty(target = hyperparam, margin = "rows", select = mask)
  rowIndex = min(nrow(hyperparam), k)
  # select the top k
  bestPipeline = pipeline[1:rowIndex,]
  bestHyperparams = hyperparam[1:rowIndex,]  
}

# extract the top k pipelines for each bracket, the intermediate results
extractBracketWinners = function(Matrix[Double] pipeline, Matrix[Double] hyperparam, 
  Integer k, Frame[String] conf)
  return (Frame[Unknown] bestPipeline, Matrix[Double] bestHyperparams)
{
  # bestPipeline = frameSort(bestPipeline)
  hyperparam = order(target = hyperparam, by = 1, decreasing=TRUE, index.return=FALSE)
  pipeline = order(target = pipeline, by = 1, decreasing=TRUE, index.return=FALSE)
  rowIndex = min(k, nrow(pipeline))

  pipeline = pipeline[1:rowIndex,]
  bestHyperparams = hyperparam[1:rowIndex,]
  bestPipeline = frame(data="|", rows=nrow(pipeline), cols=ncol(conf))
  parfor(i in 1: nrow(pipeline)) {
    index = as.scalar(pipeline[i, 3])
    bestPipeline[i] = conf[index]
    bestPipeline[i, 1] = as.frame(pipeline[i, 1])
  }
}

###########################################################################
# The function will return the max performance by each individual pipeline
############################################################################
getMaxPerConf = function(Matrix[Double] pipelines, Double size)
return (Frame[Unknown] maxperconf)
{
  tab = removeEmpty(target=table(pipelines[, 2], pipelines[, 3], pipelines[, 1]), margin="cols")
  maxperconf = frame(0, rows=size, cols=1)
  maxperconf[1:ncol(tab),] = as.frame(t(colMaxs(tab)))
}

pipToString = function(Frame[String] F)
return (String s)
{
  s = ""
  for(i in 1:ncol(F))
    s = s + as.scalar(F[1,i])+";"

}

crossV = function(Matrix[double] X, Matrix[double] y, Integer cvk, Matrix[Double] evalFunHp, List[Unknown] pipList, List[Unknown] metaList,
  Matrix[Double] hpForPruning = as.matrix(0), Matrix[Double] changesByOp = as.matrix(0), String evalFunc, Double ref = 0) 
return (Double accuracy, Matrix[Double] evalFunHp, Matrix[Double] hpForPruning, Matrix[Double] changesByOp, Double allChanges)
{

  # # in the below condition we compute the hp using cv method on train dataset
  if(is.na(as.scalar(evalFunHp[1,1]))) {
    forEvalHp = eval(evalFunc, list(X=X, Y=y, Xtest=X, Ytest=y, Xorig=as.matrix(0), evalFunHp=evalFunHp))
    evalFunHp = forEvalHp[1, 2:ncol(forEvalHp)]
  } 
  changesByPip = 0
  cvChanges = matrix(0, rows=cvk, cols=ncol(changesByOp))
  accuracyMatrix = matrix(0, cvk, 1)
  allChanges = matrix(0, cvk, 1)
  #create empty lists
  dataset_X = list(); #empty list
  dataset_y = list();
  fs = ceil(nrow(X)/cvk);
  off = fs - 1;
  #divide X, y into lists of k matrices
  for (i in seq(1, cvk)) {  
    dataset_X = append(dataset_X, X[i*fs-off : min(i*fs, nrow(X)),]);
    dataset_y = append(dataset_y, y[i*fs-off : min(i*fs, nrow(y)),]);
  }

  beta_list = list();
  #keep one fold for testing in each iteration
  for (i in seq(1, cvk)) {
    [tmpX, testX] = remove(dataset_X, i); 
    [tmpy, testy] = remove(dataset_y, i);
    trainX = rbind(tmpX);
    trainy = rbind(tmpy);
    testX = as.matrix(testX)
    testy = as.matrix(testy)
    if(as.scalar(pipList['flags']) != 0)  # this flag is zero when CV is called from the dirtyScore function, means only accuracy calculation but no pipeline execution
    {
      [trainX, trainy, testX, testy, Tr, hpForPruning, changesByOp, changesByPip] = executePipeline(pipeline=as.frame(pipList['ph']),
        Xtrain=trainX, Ytrain=trainy, Xtest= testX, Ytest=testy, metaList=metaList, hyperParameters=as.matrix(pipList['hp']), hpForPruning=hpForPruning,
        changesByOp=changesByOp, flagsCount=as.scalar(pipList['flags']), test=TRUE, verbose=FALSE)
      cvChanges[cvk] = changesByOp
      allChanges[i] =  changesByPip
    }
    if(changesByPip < ref)
      print("prunning alert 2: no training the model due to minimum changes")
    else { 
      res = eval(evalFunc, list(X=trainX, Y=trainy, Xtest=testX, Ytest=testy, Xorig=as.matrix(0), evalFunHp=evalFunHp))
      accuracyMatrix[i] = res[1, 1]
    }
    
  }
  allChanges = min(allChanges)
  changesByOp = colMaxs(cvChanges)
  accuracy =  mean(accuracyMatrix)
  print("cv accuracy: "+toString(accuracy))
}

pruningSignal = function(Frame[Unknown] ph_pip, Matrix[Double] hp_matrix, Matrix[Double] hpForPruning, Matrix[Double] changesByOp)
return(Boolean execute)
{
  execute = TRUE
  prune = (hpForPruning > 0) & (changesByOp == 0)
  changeCount = 0
  # # if there exist a case where the changes done by an operation are zeros
  if(sum(prune) > 0)
  {
    # get the non-zero index of hpForPruning
    idx = (hpForPruning > 0) * t(seq(1, ncol(hpForPruning)))
    idx = removeEmpty(target=idx, margin="cols")
    for(i in 1:ncol(idx)) {
      index = as.scalar(idx[1, i])
      inProcessHp = as.scalar(hp_matrix[index, 2])
      prvHp = as.scalar(hpForPruning[1, index])
      if(inProcessHp > prvHp)
        changeCount = changeCount + 1
    }
  }
  execute = !(changeCount > 0)
}

getParamMeta = function(Frame[Unknown] pipeline, Frame[Unknown] hpList)
return(Frame[Unknown] applyFunc, Matrix[Double] indexes, Matrix[Double] paramCount)
{
  # print("pipeline in meta "+toString(pipeline))
  # while(FALSE){}
  indexes = matrix(0, rows= ncol(pipeline), cols=1)
  paramCount = matrix(0, rows= ncol(pipeline), cols=1)
  applyList = hpList[, 1]
  applyFunc = pipeline
  parfor(k in 1:ncol(pipeline))
  {
    op = as.scalar(pipeline[1,k])
    hasParam = map(hpList[,2], "x->x.split(\",\")[0].equals(\""+op+"\")")
    # convert the boolean vector to 0/1 matrix representation
    m_hasParam = hasParam == frame("true", rows=nrow(hasParam), cols=1)
    m_hasParam = as.matrix(m_hasParam)
    # compute the relevant index
    index = m_hasParam * seq(1, nrow(m_hasParam))
    index = as.scalar(removeEmpty(target = index, margin = "rows"))
    indexes[k] = index
    paramCount[k] = as.integer(as.scalar(hpList[index, 3]))
    applyFunc[1, k] = as.scalar(hpList[index, 1])
  }
}
