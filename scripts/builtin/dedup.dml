#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
#-------------------------------------------------------------

# Builtin for deduplication using distributed representations (DRs) and
# locality-sensitive hashing (LSH) based blocking.
#
# The function encodes each input tuple as a dense vector using pre-trained GloVe embeddings (simple averaging), 
# groups semantically similar tuples via LSH into buckets, and compares only those pairs for deduplication.
# 
#
# INPUT:
# --------------------------------------------------------------------------------------
# X                 Input Frame[String] with n rows and d columns (raw tuples)
# gloveMatrix       Matrix[Double] of size |V| × e (pretrained GloVe embeddings) -> |V| number of words and e = embedding dimesnion
# vocab             Matrix[String] of size |V| × 1 (vocabulary aligned with gloveMatrix)
# similarityMeasure String specifying similarity metric: "cosine", "euclidean", etc.
# returnDuplicates  Boolean: if TRUE, return only detected duplicate rows;
#                   if FALSE, return input minus all detected duplicates
# --------------------------------------------------------------------------------------
#
# OUTPUT:
# --------------------------------------------------------------------------------------
# Y    Frame[String] of deduplicated or duplicate-only tuples
# --------------------------------------------------------------------------------------


dedup = function(Frame[String] X, Matrix[Double] gloveMatrix, Matrix[String] vocab, String similarityMeasure, Boolean returnDuplicates)
  return(Frame[String] FinalData)
{
  # Step 1: Distributed Representation (DRs)
  V = computeDRMatrix(X, vocab, gloveMatrix)

  # Step 2: generate LSH Hyperplanes
  K = 10 # number of hash functions
  d = nCol(V)
  H = rand(rows=K, cols=d, pdf="normal", seed=-1)

  # Step 3: Compute LSH Hashcodes
  hashcodes = computeLSH(V, H)

  # Step 4: Form Buckets 

  # Step 5: Candidate Pair Generation

  # Step 6: COmpute Similarity for Pairs

  # Step 7: Filter Duplicates 

  # Step 8: Return according to flag


}

computeDRMatrix = function(Frame[String] X, Matrix[String] vocab, Matrix[Double] gloveMatrix)
  return (Matrix[Double] V)
  {
    n = nrow(X)
    d = ncol(gloveMatrix)
    V = matrix(0, rows=n, cols=d) # define output matrix

    for (i in 1:n) {
      line = concat(X[i,])              # z. B. "Bill Gates Seattle"
      clean = lowerCase(trim(line))     # "bill gates seattle"
      words = strsplit(clean, " ")      # [ "bill", "gates", "seattle" ]

      sumVec = matrix(0, rows=1, cols=d)
      count = 0

      for (k in 1:length(words)) {
        w = words[k]
        idx = -1

        # search for word in vocabulary
        for (m in 1:nrow(vocab)) {
          if (vocab[m,1] == w) {  # TODO: better solution ?
            idx = m 
            break
          }
        }
        # word found 
        if (idx > 0) {
          sumVec = sumVec + gloveMatrix[idx,]
          count = count + 1
        }
      }
      if (count > 0) {
        V[i,] = sumVec / count
      }
      else {
        V[i,] = sumVec
      }
    }
  }

computeLSH = function(Matrix[Double] V, Matrix[Double] H)
  return (Matrix[Int] hashCodes)
  {
    # matrix multiplication: projection of each DR vector on hyperplanes
    P = V %*% t(H) 
    # if 0 -> 0*2-1 = -1
    # if 1 -> 1*2-1 = 1
    hashCodes = (P > 0) * 2 - 1 
  }
  

# extractDuplicates

# removeDuplicates


