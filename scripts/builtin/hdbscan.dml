#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
#-------------------------------------------------------------

# The hdbscan function is used to perform the hdbscan clustering
# algorithm using knn-based mutual reachability distance and minimum spanning tree.
#
# INPUT:
# ------------------------------------------------------------
# X             The input Matrix to do hdbscan on.
# minPts        Minimum number of points for core distance computation. (Defaults to 5)
# minClSize     Minimum cluster size (Defaults to minPts)              
# ------------------------------------------------------------
#
# OUTPUT:
# ------------------------------------------------------------
# clusterMems   Cluster labels for each point
# clusterModel  The cluster centroids for prediction
# ------------------------------------------------------------

# TODO: m,s , f?
m_hdbscan = function(Matrix[Double] X, Integer minPts = 5, Integer minClSize = -1)
    return (Matrix[Double] clusterMems, Matrix[Double] clusterModel)
{
    if(minPts < 2) {
        stop("HDBSCAN: minPts should be at least 2")
    }

    if(minClSize < 0) {
        minClSize = minPts
    }

    n = nrow(X)
    d = ncol(X)

    if(n < minPts) {
        stop("HDBSCAN: Number of data points should be at least minPts")
    }

    distances = dist(X)

    coreDistances = matrix(0, rows=n, cols=1)
    for(i in 1:n) {
        kthDist = computeKthSmallest(distances[i,], minPts)
        coreDistances[i] = kthDist
    }
   
    mutualReachDist = computeMutualReachability(distances, coreDistances)

    [mstEdges, mstWeights] = buildMST(mutualReachDist, n)

    [hierarchy, clusterSizes] = buildHierarchy(mstEdges, mstWeights, n)

    # TODO: get stable cluster with stability score
    # TODO: build cluster model
    
    # temp  dummy values
    clusterMems = matrix(1, rows=n, cols=1)
    clusterModel = X
}


computeKthSmallest = function(Matrix[Double] array, Integer k)
    return (Double res)
{
  sorted = order(target=array, by=1, decreasing=FALSE)
  res = as.scalar(sorted[k+1, 1])
}


computeMutualReachability = function(Matrix[Double] distances, Matrix[Double] coreDistances)
    return (Matrix[Double] mutualReach)
{
    # mutualReach(i,j) = max(dist(i,j), coreDist(i), coreDist(j))
    # Diagonal is set to zero.

    n = nrow(distances)
  
    coreDistRow = t(coreDistances)
    coreDistCol = coreDistances
  
    maxCoreRow = (distances > coreDistRow) * distances + (distances <= coreDistRow) * coreDistRow
    mutualReach = (maxCoreRow > coreDistCol) * maxCoreRow + (maxCoreRow <= coreDistCol) * coreDistCol
  
    mutualReach = mutualReach * (1 - diag(matrix(1, rows=n, cols=1)))
}


buildMST = function(Matrix[Double] distances, Integer n)
    return (Matrix[Double] edges, Matrix[Double] weights)
{
  edges = matrix(0, rows=n-1, cols=2)
  weights = matrix(0, rows=n-1, cols=1)
  
  inMST = matrix(0, rows=n, cols=1)
  inMST[1] = 1
  
  minDist = distances[1,]
  minDist = t(minDist)
  
  for(i in 1:(n-1)) {
    candidates = minDist + inMST * 1e15 
    minIdx = as.scalar(rowIndexMin(t(candidates)))
    minWeight = as.scalar(minDist[minIdx])
    
    # Find which node in MST connects to minIdx
    connectIdx = as.scalar(rowIndexMin(distances[minIdx,] + t(1-inMST) * 1e15))
    edges[i,1] = minIdx
    edges[i,2] = connectIdx
    weights[i] = minWeight
    
    inMST[minIdx] = 1
    newDists = distances[minIdx,]
    minDist = (minDist < t(newDists)) * minDist + (minDist >= t(newDists)) * t(newDists)
  }
}

# Union-find utils

find = function(Matrix[Double] parent, Integer x)
    return (Integer root)
{
    root = x
    while(as.scalar(parent[root]) != root) {
        root = as.integer(as.scalar(parent[root]))
    }
}

union = function(Matrix[Double] parent, Matrix[Double] rank,
                Integer x, Integer y, Matrix[Double] size,
                Matrix[Double] compToNode, Integer newId)
    return (Matrix[Double] newParent, Matrix[Double] newRank,
            Matrix[Double] newSize, Matrix[Double] newCompToNode, Integer newRoot)
{
    newParent = parent
    newRank = rank
    newSize = size
    newCompToNode = compToNode

    rankX = as.scalar(rank[x,1])
    rankY = as.scalar(rank[y,1])

    combinedSize = as.scalar(size[x,1]) + as.scalar(size[y,1])

    if(rankX < rankY) {
        newParent[x] = y
        newSize[y,1] = combinedSize
        newCompToNode[y,1] = newId
        newRoot = y
    }
    else if(rankX > rankY) {
        newParent[y] = x
        newSize[x,1] = combinedSize
        newCompToNode[x,1] = newId
        newRoot = x
    }
    else {
        newParent[y] = x
        newRank[x,1] = rankX + 1
        newSize[x,1] = combinedSize
        newCompToNode[x,1] = newId
        newRoot = x
    }
}


buildHierarchy = function(Matrix[Double] edges, Matrix[Double] weights, Integer n)
    return (Matrix[Double] hierarchy, Matrix[Double] sizes)
{
    # sort edges by weight in ascending order
    # to build the hierarchy from dense cores outward
    sorted = order(target=weights, by=1, decreasing=FALSE)

    # parent[i] = i, meaning each point is its own parent in the beginning
    parent = seq(1, n)
    # tree depth when unioning (icnreases only when merged trees are of same height)
    rank = matrix(0, rows=n, cols=1)

    # initially, each component is a single point, so root i maps to leaf node i.
    # Later, when two components merge, the new component root will map to a new
    # internal linkage node id (n+1, n+2, ..., 2n-1)
    compToNode = seq(1, n)

    # size (number of original points) for each linkage-tree node id,
    # leaves 1..n have size 1.
    nodeSize = matrix(0, rows=2*n-1, cols=1)
    for(j in 1:n) {
        nodeSize[j,1] = 1
    }

    # hierarcy[i, :] = [cluster1_id, cluster2_id, merge_distance]
    hierarchy = matrix(0, rows=n-1, cols=3)

    # sizes[i] = size of the cluster created by merge i
    sizes = matrix(0, rows=n-1, cols=1)

    row = 1
    for(i in 1:(n-1)) {
        idx = as.integer(as.scalar(sorted[i,1]))
        u = as.integer(as.scalar(edges[idx,1]))
        v = as.integer(as.scalar(edges[idx,2]))
        w = as.scalar(weights[idx,1])

        root_u = find(parent, u)
        root_v = find(parent, v)

        if(root_u != root_v) {
            left  = as.integer(as.scalar(compToNode[root_u]))
            right = as.integer(as.scalar(compToNode[root_v]))

            newId = n + row

            hierarchy[row,1] = left
            hierarchy[row,2] = right
            hierarchy[row,3] = w

            nodeSize[newId,1] = as.scalar(nodeSize[left,1]) + as.scalar(nodeSize[right,1])
            sizes[row,1] = as.scalar(nodeSize[newId,1])

            [parent, rank, ufSize, compToNode, newRoot] =
                union(parent, rank, root_u, root_v, nodeSize, compToNode, newId)

            row = row + 1
        }
    }
}
