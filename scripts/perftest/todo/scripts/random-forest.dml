#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
#-------------------------------------------------------------

#  
# THIS SCRIPT IMPLEMENTS CLASSIFICATION RANDOM FOREST WITH BOTH SCALE AND CATEGORICAL FEATURES
#
# INPUT         		PARAMETERS:
# ---------------------------------------------------------------------------------------------
# NAME          		TYPE     DEFAULT      MEANING
# ---------------------------------------------------------------------------------------------
# X             		String   ---          Location to read feature matrix X; note that X needs to be both recoded and dummy coded 
# Y 					String   ---		  Location to read label matrix Y; note that Y needs to be both recoded and dummy coded
# R   	  				String   " "	      Location to read the matrix R which for each feature in X contains the following information 
#												- R[,1]: column ids
#												- R[,2]: start indices 
#												- R[,3]: end indices
#											  If R is not provided by default all variables are assumed to be scale
# bins          		Int 	 20			  Number of equiheight bins per scale feature to choose thresholds
# depth         		Int 	 25			  Maximum depth of the learned tree
# num_leaf      		Int      10           Number of samples when splitting stops and a leaf node is added
# num_samples   		Int 	 3000		  Number of samples at which point we switch to in-memory subtree building
# num_trees     		Int 	 10			  Number of trees to be learned in the random forest model
# subsamp_rate  		Double   1.0		  Parameter controlling the size of each tree in the forest; samples are selected from a 
#											  Poisson distribution with parameter subsamp_rate (the default value is 1.0)
# feature_subset    	Double   0.5    	  Parameter that controls the number of feature used as candidates for splitting at each tree node 
#											  as a power of number of features in the dataset;
#											  by default square root of features (i.e., feature_subset = 0.5) are used at each tree node 
# impurity      		String   "Gini"    	  Impurity measure: entropy or Gini (the default)
# M             		String 	 ---	   	  Location to write matrix M containing the learned tree
# C 					String   " "		  Location to write matrix C containing the number of times samples are chosen in each tree of the random forest 
# S_map					String   " "		  Location to write the mappings from scale feature ids to global feature ids
# C_map					String   " "		  Location to write the mappings from categorical feature ids to global feature ids
# fmt     	    		String   "text"       The output format of the model (matrix M), such as "text" or "csv"
# ---------------------------------------------------------------------------------------------
# OUTPUT: 
# Matrix M where each column corresponds to a node in the learned tree and each row contains the following information:
#	 M[1,j]: id of node j (in a complete binary tree)
#	 M[2,j]: tree id to which node j belongs
#	 M[3,j]: Offset (no. of columns) to left child of j 
#	 M[4,j]: Feature index of the feature that node j looks at if j is an internal node, otherwise 0
#	 M[5,j]: Type of the feature that node j looks at if j is an internal node: 1 for scale and 2 for categorical features, 
#		     otherwise the label that leaf node j is supposed to predict
#	 M[6,j]: 1 if j is an internal node and the feature chosen for j is scale, otherwise the size of the subset of values 
#			 stored in rows 7,8,... if j is categorical
#	 M[7:,j]: Only applicable for internal nodes. Threshold the example's feature value is compared to is stored at M[7,j] if the feature chosen for j is scale;
# 			  If the feature chosen for j is categorical rows 7,8,... depict the value subset chosen for j   
# -------------------------------------------------------------------------------------------
# HOW TO INVOKE THIS SCRIPT - EXAMPLE:
# hadoop jar SystemDS.jar -f random-forest.dml -nvargs X=INPUT_DIR/X Y=INPUT_DIR/Y R=INPUT_DIR/R M=OUTPUT_DIR/model
#     				                 				   bins=20 depth=25 num_leaf=10 num_samples=3000 num_trees=10 impurity=Gini fmt=csv

	
# Default values of some parameters	
fileR = ifdef ($R, " ");
fileM = $M;	
num_bins = ifdef($bins, 20); 
depth = ifdef($depth, 25);
num_leaf = ifdef($num_leaf, 10);
num_trees = ifdef($num_trees, 1); 
threshold = ifdef ($num_samples, 3000);
imp = ifdef($impurity, "Gini");
rate = ifdef ($subsamp_rate, 1);
fpow = ifdef ($feature_subset, 0.5);
fmtO = ifdef($fmt, "text");

X = read($X);
Y_bin = read($Y);
R = matrix(0, cols=0, rows=0);


# TODO: deprecated randomForest function call
[M, C, S_map, C_map] = randomForest(X = X, Y = Y_bin, R = R,
    bins = num_bins, depth = depth, num_leaf = num_leaf, num_samples = threshold,
    num_trees = num_trees, subsamp_rate = rate, feature_subset = fpow, impurity = imp);

write (M, fileM, format = fmtO);
