#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
#-------------------------------------------------------------
# Generate the logical pipelines using basic evolutionary algorithm, 
# population -> logical Pipeline, chromosome -> physical pipeline, gene -> hp
# input :
# 1. Dataset X
# 2. population, different logical seed pipelines format = [number of operators, op1, op2, op3 ..., opn]
# 3. number of iterations
# 4. pipLength, length of pipeline, number of operator in each pipeline
# 5. meta data list i.e., schema, mask, fdmask
# 6. target list i.e, target application, cv value etc.
# 7. primitives, physical operator list
# 8. param, physical operator hyperparameters
# 9. num_inst value, number of physical instances for each logical to be executed
# 10. num_exec, how many times each physical pipeline should be executed
# 11. n_pop, children created in each generation
# output: best logical pipeline and evaluation time in ms

# idea is to get the initial set of logical pipelines, as population, then get the num_inst physical pipelines foreach
# logical pipeline in population. Then execute these physical pipelines num_exec time were in each execution a random
# set of hyperparameters is used to execute operators. 
# The compute a score vector by storing the best score foreach logical pipeline in population. Sort the pipelines by
# score and take n_pop pipelines as parents for generating new population from the selected pipelines take a pair in
# each iteration as parent and generate a pair of children by doing crossover and mutation.
# There are total 3 transformation that will be performed to create a new chromosomes (children)
#   1. crossover to create children by adding n operation from p1 to p2 and vice versa. 
#   2. mutation to swap two operations in the children based on a mutation rate, swap is randomly based on mutationRatio.
#   3. removal to remove n operations from a child
# These new children will be the population in next iteration.
# Repeat the process max_iter time. Converge in between if the best_score of previous generation is better then
# best_score of new generation.


source("scripts/builtin/bandit.dml") as bandit;

enumerateLogical = function(Matrix[Double] X, Matrix[Double] y, Matrix[Double] Xtest, Matrix[Double] ytest,
  Frame[Unknown] initial_population, Integer seed = -1, Integer max_iter=10, List[Unknown] metaList, String evaluationFunc, Matrix[Double] evalFunHp,
  Frame[Unknown] primitives, Frame[Unknown] param, Double dirtyScore = 79, Boolean cv=FALSE, Boolean cvk=3,
  Boolean verbose, List[Unknown] ctx=list(prefix="----"))
return (Frame[Unknown] output, boolean converged, Double refChanges)
{

  finalOutput = list()
  mask = as.matrix(metaList['mask'])
  prefix = as.scalar(ctx["prefix"]);  
  iter = 1
  populationLength = 0
  converged = FALSE
  start = 1; 
  end = 0;
  [allOps, ref] = getOps(param[, 2], as.scalar(metaList['distY']), nrow(y), min(y))

  # unrolled by physical pipelines
  pipelines = frame(0, rows=nrow(primitives)^ncol(primitives), cols=max(ncol(initial_population), ncol(ref)))
  for(i in 1:nrow(initial_population)) { 
    pconf = bandit::get_physical_configurations(initial_population[i], 0, primitives)
    end = end + nrow(pconf)
    pipelines[start:end, 1:ncol(pconf)] = pconf
    start = end + 1
  }
  pipelines = removeEmpty(target = pipelines, margin="rows") 
  if(sum(mask) > 0)
  {
    dummyEncode = frame("dummycoding", rows=nrow(pipelines), cols=1)
    pipelines[, 2] = dummyEncode
  }
  pipelines = rbind(ref, pipelines)
  population = pipelines
  populationSize = nrow(pipelines)
  transitions = sample(3, (populationSize * max_iter), TRUE, seed)
  opToAdd = sample(nrow(allOps), (populationSize * max_iter), TRUE, seed)
  opToRemove = sample(max_iter, (populationSize * max_iter), TRUE, seed)
  refChangesInternal = 0
  while(!converged & iter <= max_iter)
  {
    populationLength = max(populationLength, ncol(population))
    id = matrix(seq(1, nrow(population)*2), rows=nrow(population), cols=2)
    print(prefix+" EnumLP iteration "+iter+"/"+as.integer(max_iter)+":" );
    # # # execute the physical pipelines
    [outPip, outHp, p, refChanges] = bandit::run_with_hyperparam(ph_pip=cbind(as.frame(id), population),
      X=X, Y=y, Xtest=Xtest, Ytest=ytest, metaList=metaList, evaluationFunc=evaluationFunc, evalFunHp=evalFunHp, param=param, cv=cv, cvk=cvk, seed=seed, default=TRUE)
    # # sort the configurations score-wise
    actPip = cbind(as.frame(outPip[, 1]), as.frame(refChanges))
    actPip = cbind(actPip, population)
    sort_mask = cbind(matrix(0, rows=1, cols=2), matrix(1, rows=1, cols=ncol(population)))
    sortedPipelines = frameSort(actPip, sort_mask, TRUE)
    converged = as.double(as.scalar(sortedPipelines[1, 1])) > dirtyScore
    if(converged)
      print(prefix+" EnumLP  converged after "+iter+" / "+max_iter+" iterations")  
    diR = round(nrow(sortedPipelines)/2)
    if(nrow(sortedPipelines) > 1)
      sortedPipelines = sortedPipelines[1:diR]
    finalOutput = append(finalOutput, sortedPipelines)
    # # # if converged then stop otherwise generate new population
    children = frame(0, rows=populationSize, cols=ncol(sortedPipelines))
    sortedPipelines = sortedPipelines[, 3:ncol(sortedPipelines)]
    # # randomly pick the pipelines for transitions
    pipRand = sample(nrow(sortedPipelines), populationSize, TRUE, seed)
    if(!converged) {
      parfor(i in 1:nrow(children), check=0) {
        idxR = (nrow(children) * (iter - 1)) + i
        idx = as.scalar(pipRand[i])
        top = removeEmpty(target=sortedPipelines[idx], margin="cols")
        tail = top[, ncol(top)]
        if(sum(mask) > 0)
          top = top[, 1:ncol(top) - 1]
          
        random = ifelse(ncol(top) <=2, 1, as.scalar(transitions[idxR]))
        if(random == 1)
          c1 = addition(top, allOps[as.scalar(opToAdd[idxR])]) 
        else if(random == 2)
          c1 = mutation(top, seed) 
        else if(random == 3)
          c1 = removal(top, as.scalar(opToRemove[idxR])) 
        
        if(sum(mask) > 0)
          c1 = cbind(c1, tail)
        children[i, 1:ncol(c1)] = c1
      }
    }
    population = removeEmpty(target=children, margin="cols")
    iter  = iter + 1
  }
  if(!converged) {
    print(prefix+" EnumLP did not converge after "+(iter - 1)+" / "+max_iter+" iterations")  
  }
  # # # prepare the final frame output
  output = frame(0, rows=round((populationSize/2)) * length(finalOutput) , cols=populationLength + 2) 
  start = 1; 
  end = 0;
  for(i in 1:length(finalOutput))
  {
    pipFrame = as.frame(finalOutput[i])
    end = end + nrow(pipFrame)
    output[start:end, 1:ncol(pipFrame)] = pipFrame
    start = end + 1
  }
  sort_mask = cbind(matrix(0, rows=1, cols=2), matrix(1, rows=1, cols=ncol(output) - 2))
  output = removeEmpty(target=output, margin="rows")
  output = frameSort(output, sort_mask, FALSE)
  refChanges = as.double(as.scalar(output[nrow(output), 2]))
  # halfing = max(floor(nrow(output)/2), 1)
  output = output[,3:ncol(output)]
}

addition = function(Frame[Unknown] top, Frame[Unknown] allOps)
return (Frame [Unknown] child)
{
  child = cbind(allOps, top)
}

mutation = function(Frame[Unknown] child, Integer seed)
return (Frame [Unknown] mChild)
{
  if(ncol(child) >= 2)
  {
    r = sample(ncol(child), 2, FALSE, seed)
    r1 = as.scalar(r[1,1])
    r2 = as.scalar(r[2,1])
    temp = child[1, r1]
    child[1, r1] = child[1, r2]
    child[1, r2] = temp
  }
  mChild = child
}

removal = function(Frame[Unknown] child, Integer pos)
return (Frame[Unknown] child)
{
  if(ncol(child) >= 2)
  {
    pos = min(ncol(child), pos)
    child[1, pos] = as.frame(0)
    child = removeEmpty(target=child, margin="cols")
  }
}

getOps = function( Frame[string] allOps, Integer dist, Integer n, Integer minValue)
 return (Frame[String] allOps, Frame[String] ref) {
 
  # # # TODO fix the following hard-coded condition by taking a file input
  # # allOps are the operation which are randomly added to a population, for now I am reusing param file
  # # so map condition with remove the operations which should not be added twice in a pipeline i.e., dummycoding
  # # for regression class imbalance operators are also removed
  if(n > 0 & minValue >= 1 & dist <= 15) {
    allOps = map(allOps, "x -> (!x.equals(\"dummycoding\") & !x.equals(\"frequencyEncode\")
    & !x.equals(\"dbscan\") & !x.equals(\"WoE\") & !x.equals(\"pca\") & !x.equals(\"ppca\"))?x:\"0\"")
    ref = frame(["imputeByMean", "winsorize", "scale", "dummycoding"], rows=1, cols=4)
  }
  else {
    allOps = map(allOps, "x -> (!x.equals(\"dummycoding\") & !x.equals(\"frequencyEncode\") & !x.equals(\"tomeklink\")
      & !x.equals(\"dbscan\") & !x.equals(\"WoE\") & !x.equals(\"pca\") & !x.equals(\"ppca\") &
      !x.equals(\"abstain\") & !x.equals(\"underSampling\") & !x.equals(\"flipLabels\") & !x.equals(\"SMOTE\"))?x:\"0\"")
    # & !x.equals(\"mice\") & !x.equals(\"dbscan\")
    ref = frame(["imputeByMean", "winsorize", "scale"], rows=1, cols=3)
  }
  allOps = removeEmpty(target=allOps, margin="rows")
}