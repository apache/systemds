//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-30978841
// Cuda compilation tools, release 11.6, V11.6.112
// Based on NVVM 7.0.1
//

.version 7.6
.target sm_52
.address_size 64

	// .globl	double2float_f
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.extern .shared .align 16 .b8 memory[];
.global .align 1 .b8 $str[28] = {84, 66, 73, 58, 32, 118, 97, 108, 95, 115, 112, 97, 114, 115, 101, 95, 114, 99, 40, 37, 100, 44, 32, 37, 100, 41, 10, 0};

.visible .entry double2float_f(
	.param .u64 double2float_f_param_0,
	.param .u64 double2float_f_param_1,
	.param .u32 double2float_f_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<6>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd1, [double2float_f_param_0];
	ld.param.u64 	%rd2, [double2float_f_param_1];
	ld.param.u32 	%r2, [double2float_f_param_2];
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r3, %r4, %r5;
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB0_2;

	cvta.to.global.u64 	%rd3, %rd1;
	mul.wide.s32 	%rd4, %r1, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f64 	%fd1, [%rd5];
	cvt.rn.f32.f64 	%f1, %fd1;
	cvta.to.global.u64 	%rd6, %rd2;
	mul.wide.s32 	%rd7, %r1, 4;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f32 	[%rd8], %f1;

$L__BB0_2:
	ret;

}
	// .globl	float2double_f
.visible .entry float2double_f(
	.param .u64 float2double_f_param_0,
	.param .u64 float2double_f_param_1,
	.param .u32 float2double_f_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<6>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd1, [float2double_f_param_0];
	ld.param.u64 	%rd2, [float2double_f_param_1];
	ld.param.u32 	%r2, [float2double_f_param_2];
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r3, %r4, %r5;
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB1_2;

	cvta.to.global.u64 	%rd3, %rd1;
	mul.wide.s32 	%rd4, %r1, 4;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f32 	%f1, [%rd5];
	cvt.f64.f32 	%fd1, %f1;
	cvta.to.global.u64 	%rd6, %rd2;
	mul.wide.s32 	%rd7, %r1, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd1;

$L__BB1_2:
	ret;

}
	// .globl	reduce_sum_f
.visible .entry reduce_sum_f(
	.param .u64 reduce_sum_f_param_0,
	.param .u64 reduce_sum_f_param_1,
	.param .u32 reduce_sum_f_param_2
)
{
	.local .align 8 .b8 	__local_depot2[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<25>;
	.reg .f32 	%f<69>;
	.reg .b32 	%r<26>;
	.reg .b64 	%rd<42>;


	mov.u64 	%SPL, __local_depot2;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd12, [reduce_sum_f_param_0];
	ld.param.u64 	%rd13, [reduce_sum_f_param_1];
	ld.param.u32 	%r15, [reduce_sum_f_param_2];
	mov.u32 	%r1, %ntid.x;
	shl.b32 	%r16, %r1, 1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	mad.lo.s32 	%r23, %r16, %r2, %r3;
	mov.u32 	%r17, %nctaid.x;
	mul.lo.s32 	%r5, %r16, %r17;
	setp.ge.u32 	%p1, %r23, %r15;
	mov.f32 	%f51, 0f00000000;
	@%p1 bra 	$L__BB2_12;

	cvta.to.global.u64 	%rd14, %rd12;
	ld.global.u64 	%rd1, [%rd14+16];
	setp.eq.s64 	%p2, %rd1, 0;
	ld.global.u64 	%rd2, [%rd14+32];
	@%p2 bra 	$L__BB2_9;

	mov.u64 	%rd39, %rd1;

$L__BB2_3:
	mul.wide.u32 	%rd15, %r23, 4;
	add.s64 	%rd16, %rd39, %rd15;
	ld.u32 	%r18, [%rd16];
	mul.wide.u32 	%rd17, %r18, 4;
	add.s64 	%rd18, %rd2, %rd17;
	ld.f32 	%f35, [%rd18];
	add.f32 	%f51, %f51, %f35;
	add.s32 	%r24, %r23, %r1;
	setp.ge.u32 	%p3, %r24, %r15;
	@%p3 bra 	$L__BB2_7;

	setp.eq.s64 	%p4, %rd39, 0;
	mov.u64 	%rd39, 0;
	@%p4 bra 	$L__BB2_6;

	mul.wide.u32 	%rd20, %r24, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.u32 	%r24, [%rd21];
	mov.u64 	%rd39, %rd1;

$L__BB2_6:
	mul.wide.u32 	%rd22, %r24, 4;
	add.s64 	%rd23, %rd2, %rd22;
	ld.f32 	%f36, [%rd23];
	add.f32 	%f51, %f51, %f36;

$L__BB2_7:
	add.s32 	%r23, %r23, %r5;
	setp.lt.u32 	%p5, %r23, %r15;
	@%p5 bra 	$L__BB2_3;
	bra.uni 	$L__BB2_12;

$L__BB2_9:
	mul.wide.u32 	%rd24, %r23, 4;
	add.s64 	%rd25, %rd2, %rd24;
	ld.f32 	%f38, [%rd25];
	add.f32 	%f51, %f51, %f38;
	add.s32 	%r12, %r23, %r1;
	setp.ge.u32 	%p6, %r12, %r15;
	@%p6 bra 	$L__BB2_11;

	mul.wide.u32 	%rd26, %r12, 4;
	add.s64 	%rd27, %rd2, %rd26;
	ld.f32 	%f39, [%rd27];
	add.f32 	%f51, %f51, %f39;

$L__BB2_11:
	add.s32 	%r23, %r23, %r5;
	setp.lt.u32 	%p7, %r23, %r15;
	@%p7 bra 	$L__BB2_9;

$L__BB2_12:
	shl.b32 	%r19, %r3, 2;
	mov.u32 	%r20, memory;
	add.s32 	%r14, %r20, %r19;
	st.shared.f32 	[%r14], %f51;
	bar.sync 	0;
	setp.lt.u32 	%p8, %r1, 1024;
	@%p8 bra 	$L__BB2_16;

	setp.gt.u32 	%p9, %r3, 511;
	@%p9 bra 	$L__BB2_15;

	ld.shared.f32 	%f40, [%r14+2048];
	add.f32 	%f51, %f51, %f40;
	st.shared.f32 	[%r14], %f51;

$L__BB2_15:
	bar.sync 	0;

$L__BB2_16:
	setp.lt.u32 	%p10, %r1, 512;
	@%p10 bra 	$L__BB2_20;

	setp.gt.u32 	%p11, %r3, 255;
	@%p11 bra 	$L__BB2_19;

	ld.shared.f32 	%f41, [%r14+1024];
	add.f32 	%f51, %f51, %f41;
	st.shared.f32 	[%r14], %f51;

$L__BB2_19:
	bar.sync 	0;

$L__BB2_20:
	setp.lt.u32 	%p12, %r1, 256;
	@%p12 bra 	$L__BB2_24;

	setp.gt.u32 	%p13, %r3, 127;
	@%p13 bra 	$L__BB2_23;

	ld.shared.f32 	%f42, [%r14+512];
	add.f32 	%f51, %f51, %f42;
	st.shared.f32 	[%r14], %f51;

$L__BB2_23:
	bar.sync 	0;

$L__BB2_24:
	setp.lt.u32 	%p14, %r1, 128;
	@%p14 bra 	$L__BB2_28;

	setp.gt.u32 	%p15, %r3, 63;
	@%p15 bra 	$L__BB2_27;

	ld.shared.f32 	%f43, [%r14+256];
	add.f32 	%f51, %f51, %f43;
	st.shared.f32 	[%r14], %f51;

$L__BB2_27:
	bar.sync 	0;

$L__BB2_28:
	setp.gt.u32 	%p16, %r3, 31;
	@%p16 bra 	$L__BB2_41;

	setp.lt.u32 	%p17, %r1, 64;
	@%p17 bra 	$L__BB2_31;

	ld.volatile.shared.f32 	%f44, [%r14+128];
	add.f32 	%f51, %f51, %f44;
	st.volatile.shared.f32 	[%r14], %f51;

$L__BB2_31:
	setp.lt.u32 	%p18, %r1, 32;
	@%p18 bra 	$L__BB2_33;

	ld.volatile.shared.f32 	%f45, [%r14+64];
	add.f32 	%f51, %f51, %f45;
	st.volatile.shared.f32 	[%r14], %f51;

$L__BB2_33:
	setp.lt.u32 	%p19, %r1, 16;
	@%p19 bra 	$L__BB2_35;

	ld.volatile.shared.f32 	%f46, [%r14+32];
	add.f32 	%f51, %f51, %f46;
	st.volatile.shared.f32 	[%r14], %f51;

$L__BB2_35:
	setp.lt.u32 	%p20, %r1, 8;
	@%p20 bra 	$L__BB2_37;

	ld.volatile.shared.f32 	%f47, [%r14+16];
	add.f32 	%f51, %f51, %f47;
	st.volatile.shared.f32 	[%r14], %f51;

$L__BB2_37:
	setp.lt.u32 	%p21, %r1, 4;
	@%p21 bra 	$L__BB2_39;

	ld.volatile.shared.f32 	%f48, [%r14+8];
	add.f32 	%f51, %f51, %f48;
	st.volatile.shared.f32 	[%r14], %f51;

$L__BB2_39:
	setp.lt.u32 	%p22, %r1, 2;
	@%p22 bra 	$L__BB2_41;

	ld.volatile.shared.f32 	%f49, [%r14+4];
	add.f32 	%f50, %f51, %f49;
	st.volatile.shared.f32 	[%r14], %f50;

$L__BB2_41:
	setp.ne.s32 	%p23, %r3, 0;
	@%p23 bra 	$L__BB2_46;

	ld.shared.f32 	%f32, [memory];
	cvta.to.global.u64 	%rd28, %rd13;
	add.s64 	%rd8, %rd28, 16;
	ld.global.u64 	%rd29, [%rd28+16];
	setp.eq.s64 	%p24, %rd29, 0;
	@%p24 bra 	$L__BB2_44;

	add.u64 	%rd30, %SP, 0;
	add.u64 	%rd31, %SPL, 0;
	mov.u32 	%r21, 0;
	st.local.v2.u32 	[%rd31], {%r21, %r2};
	mov.u64 	%rd32, $str;
	cvta.global.u64 	%rd33, %rd32;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd33;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd30;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r22, [retval0+0];
	} // callseq 0
	// begin inline asm
	trap;
	// end inline asm
	ld.global.u64 	%rd41, [%rd8+16];
	bra.uni 	$L__BB2_45;

$L__BB2_44:
	ld.global.u64 	%rd34, [%rd8+16];
	mul.wide.u32 	%rd35, %r2, 4;
	add.s64 	%rd41, %rd34, %rd35;

$L__BB2_45:
	st.f32 	[%rd41], %f32;

$L__BB2_46:
	ret;

}
	// .globl	reduce_sum_d
.visible .entry reduce_sum_d(
	.param .u64 reduce_sum_d_param_0,
	.param .u64 reduce_sum_d_param_1,
	.param .u32 reduce_sum_d_param_2
)
{
	.local .align 8 .b8 	__local_depot3[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<25>;
	.reg .b32 	%r<26>;
	.reg .f64 	%fd<69>;
	.reg .b64 	%rd<42>;


	mov.u64 	%SPL, __local_depot3;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd12, [reduce_sum_d_param_0];
	ld.param.u64 	%rd13, [reduce_sum_d_param_1];
	ld.param.u32 	%r15, [reduce_sum_d_param_2];
	mov.u32 	%r1, %ntid.x;
	shl.b32 	%r16, %r1, 1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	mad.lo.s32 	%r23, %r16, %r2, %r3;
	mov.u32 	%r17, %nctaid.x;
	mul.lo.s32 	%r5, %r16, %r17;
	setp.ge.u32 	%p1, %r23, %r15;
	mov.f64 	%fd51, 0d0000000000000000;
	@%p1 bra 	$L__BB3_12;

	cvta.to.global.u64 	%rd14, %rd12;
	ld.global.u64 	%rd1, [%rd14+16];
	setp.eq.s64 	%p2, %rd1, 0;
	ld.global.u64 	%rd2, [%rd14+32];
	@%p2 bra 	$L__BB3_9;

	mov.u64 	%rd39, %rd1;

$L__BB3_3:
	mul.wide.u32 	%rd15, %r23, 4;
	add.s64 	%rd16, %rd39, %rd15;
	ld.u32 	%r18, [%rd16];
	mul.wide.u32 	%rd17, %r18, 8;
	add.s64 	%rd18, %rd2, %rd17;
	ld.f64 	%fd35, [%rd18];
	add.f64 	%fd51, %fd51, %fd35;
	add.s32 	%r24, %r23, %r1;
	setp.ge.u32 	%p3, %r24, %r15;
	@%p3 bra 	$L__BB3_7;

	setp.eq.s64 	%p4, %rd39, 0;
	mov.u64 	%rd39, 0;
	@%p4 bra 	$L__BB3_6;

	mul.wide.u32 	%rd20, %r24, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.u32 	%r24, [%rd21];
	mov.u64 	%rd39, %rd1;

$L__BB3_6:
	mul.wide.u32 	%rd22, %r24, 8;
	add.s64 	%rd23, %rd2, %rd22;
	ld.f64 	%fd36, [%rd23];
	add.f64 	%fd51, %fd51, %fd36;

$L__BB3_7:
	add.s32 	%r23, %r23, %r5;
	setp.lt.u32 	%p5, %r23, %r15;
	@%p5 bra 	$L__BB3_3;
	bra.uni 	$L__BB3_12;

$L__BB3_9:
	mul.wide.u32 	%rd24, %r23, 8;
	add.s64 	%rd25, %rd2, %rd24;
	ld.f64 	%fd38, [%rd25];
	add.f64 	%fd51, %fd51, %fd38;
	add.s32 	%r12, %r23, %r1;
	setp.ge.u32 	%p6, %r12, %r15;
	@%p6 bra 	$L__BB3_11;

	mul.wide.u32 	%rd26, %r12, 8;
	add.s64 	%rd27, %rd2, %rd26;
	ld.f64 	%fd39, [%rd27];
	add.f64 	%fd51, %fd51, %fd39;

$L__BB3_11:
	add.s32 	%r23, %r23, %r5;
	setp.lt.u32 	%p7, %r23, %r15;
	@%p7 bra 	$L__BB3_9;

$L__BB3_12:
	shl.b32 	%r19, %r3, 3;
	mov.u32 	%r20, memory;
	add.s32 	%r14, %r20, %r19;
	st.shared.f64 	[%r14], %fd51;
	bar.sync 	0;
	setp.lt.u32 	%p8, %r1, 1024;
	@%p8 bra 	$L__BB3_16;

	setp.gt.u32 	%p9, %r3, 511;
	@%p9 bra 	$L__BB3_15;

	ld.shared.f64 	%fd40, [%r14+4096];
	add.f64 	%fd51, %fd51, %fd40;
	st.shared.f64 	[%r14], %fd51;

$L__BB3_15:
	bar.sync 	0;

$L__BB3_16:
	setp.lt.u32 	%p10, %r1, 512;
	@%p10 bra 	$L__BB3_20;

	setp.gt.u32 	%p11, %r3, 255;
	@%p11 bra 	$L__BB3_19;

	ld.shared.f64 	%fd41, [%r14+2048];
	add.f64 	%fd51, %fd51, %fd41;
	st.shared.f64 	[%r14], %fd51;

$L__BB3_19:
	bar.sync 	0;

$L__BB3_20:
	setp.lt.u32 	%p12, %r1, 256;
	@%p12 bra 	$L__BB3_24;

	setp.gt.u32 	%p13, %r3, 127;
	@%p13 bra 	$L__BB3_23;

	ld.shared.f64 	%fd42, [%r14+1024];
	add.f64 	%fd51, %fd51, %fd42;
	st.shared.f64 	[%r14], %fd51;

$L__BB3_23:
	bar.sync 	0;

$L__BB3_24:
	setp.lt.u32 	%p14, %r1, 128;
	@%p14 bra 	$L__BB3_28;

	setp.gt.u32 	%p15, %r3, 63;
	@%p15 bra 	$L__BB3_27;

	ld.shared.f64 	%fd43, [%r14+512];
	add.f64 	%fd51, %fd51, %fd43;
	st.shared.f64 	[%r14], %fd51;

$L__BB3_27:
	bar.sync 	0;

$L__BB3_28:
	setp.gt.u32 	%p16, %r3, 31;
	@%p16 bra 	$L__BB3_41;

	setp.lt.u32 	%p17, %r1, 64;
	@%p17 bra 	$L__BB3_31;

	ld.volatile.shared.f64 	%fd44, [%r14+256];
	add.f64 	%fd51, %fd51, %fd44;
	st.volatile.shared.f64 	[%r14], %fd51;

$L__BB3_31:
	setp.lt.u32 	%p18, %r1, 32;
	@%p18 bra 	$L__BB3_33;

	ld.volatile.shared.f64 	%fd45, [%r14+128];
	add.f64 	%fd51, %fd51, %fd45;
	st.volatile.shared.f64 	[%r14], %fd51;

$L__BB3_33:
	setp.lt.u32 	%p19, %r1, 16;
	@%p19 bra 	$L__BB3_35;

	ld.volatile.shared.f64 	%fd46, [%r14+64];
	add.f64 	%fd51, %fd51, %fd46;
	st.volatile.shared.f64 	[%r14], %fd51;

$L__BB3_35:
	setp.lt.u32 	%p20, %r1, 8;
	@%p20 bra 	$L__BB3_37;

	ld.volatile.shared.f64 	%fd47, [%r14+32];
	add.f64 	%fd51, %fd51, %fd47;
	st.volatile.shared.f64 	[%r14], %fd51;

$L__BB3_37:
	setp.lt.u32 	%p21, %r1, 4;
	@%p21 bra 	$L__BB3_39;

	ld.volatile.shared.f64 	%fd48, [%r14+16];
	add.f64 	%fd51, %fd51, %fd48;
	st.volatile.shared.f64 	[%r14], %fd51;

$L__BB3_39:
	setp.lt.u32 	%p22, %r1, 2;
	@%p22 bra 	$L__BB3_41;

	ld.volatile.shared.f64 	%fd49, [%r14+8];
	add.f64 	%fd50, %fd51, %fd49;
	st.volatile.shared.f64 	[%r14], %fd50;

$L__BB3_41:
	setp.ne.s32 	%p23, %r3, 0;
	@%p23 bra 	$L__BB3_46;

	ld.shared.f64 	%fd32, [memory];
	cvta.to.global.u64 	%rd28, %rd13;
	add.s64 	%rd8, %rd28, 16;
	ld.global.u64 	%rd29, [%rd28+16];
	setp.eq.s64 	%p24, %rd29, 0;
	@%p24 bra 	$L__BB3_44;

	add.u64 	%rd30, %SP, 0;
	add.u64 	%rd31, %SPL, 0;
	mov.u32 	%r21, 0;
	st.local.v2.u32 	[%rd31], {%r21, %r2};
	mov.u64 	%rd32, $str;
	cvta.global.u64 	%rd33, %rd32;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd33;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd30;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r22, [retval0+0];
	} // callseq 1
	// begin inline asm
	trap;
	// end inline asm
	ld.global.u64 	%rd41, [%rd8+16];
	bra.uni 	$L__BB3_45;

$L__BB3_44:
	ld.global.u64 	%rd34, [%rd8+16];
	mul.wide.u32 	%rd35, %r2, 8;
	add.s64 	%rd41, %rd34, %rd35;

$L__BB3_45:
	st.f64 	[%rd41], %fd32;

$L__BB3_46:
	ret;

}
	// .globl	reduce_max_f
.visible .entry reduce_max_f(
	.param .u64 reduce_max_f_param_0,
	.param .u64 reduce_max_f_param_1,
	.param .u32 reduce_max_f_param_2
)
{
	.local .align 8 .b8 	__local_depot4[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<25>;
	.reg .f32 	%f<69>;
	.reg .b32 	%r<26>;
	.reg .b64 	%rd<42>;


	mov.u64 	%SPL, __local_depot4;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd12, [reduce_max_f_param_0];
	ld.param.u64 	%rd13, [reduce_max_f_param_1];
	ld.param.u32 	%r15, [reduce_max_f_param_2];
	mov.u32 	%r1, %ntid.x;
	shl.b32 	%r16, %r1, 1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	mad.lo.s32 	%r23, %r16, %r2, %r3;
	mov.u32 	%r17, %nctaid.x;
	mul.lo.s32 	%r5, %r16, %r17;
	setp.ge.u32 	%p1, %r23, %r15;
	mov.f32 	%f51, 0fFF800000;
	@%p1 bra 	$L__BB4_12;

	cvta.to.global.u64 	%rd14, %rd12;
	ld.global.u64 	%rd1, [%rd14+16];
	setp.eq.s64 	%p2, %rd1, 0;
	ld.global.u64 	%rd2, [%rd14+32];
	@%p2 bra 	$L__BB4_9;

	mov.u64 	%rd39, %rd1;

$L__BB4_3:
	mul.wide.u32 	%rd15, %r23, 4;
	add.s64 	%rd16, %rd39, %rd15;
	ld.u32 	%r18, [%rd16];
	mul.wide.u32 	%rd17, %r18, 4;
	add.s64 	%rd18, %rd2, %rd17;
	ld.f32 	%f35, [%rd18];
	max.f32 	%f51, %f51, %f35;
	add.s32 	%r24, %r23, %r1;
	setp.ge.u32 	%p3, %r24, %r15;
	@%p3 bra 	$L__BB4_7;

	setp.eq.s64 	%p4, %rd39, 0;
	mov.u64 	%rd39, 0;
	@%p4 bra 	$L__BB4_6;

	mul.wide.u32 	%rd20, %r24, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.u32 	%r24, [%rd21];
	mov.u64 	%rd39, %rd1;

$L__BB4_6:
	mul.wide.u32 	%rd22, %r24, 4;
	add.s64 	%rd23, %rd2, %rd22;
	ld.f32 	%f36, [%rd23];
	max.f32 	%f51, %f51, %f36;

$L__BB4_7:
	add.s32 	%r23, %r23, %r5;
	setp.lt.u32 	%p5, %r23, %r15;
	@%p5 bra 	$L__BB4_3;
	bra.uni 	$L__BB4_12;

$L__BB4_9:
	mul.wide.u32 	%rd24, %r23, 4;
	add.s64 	%rd25, %rd2, %rd24;
	ld.f32 	%f38, [%rd25];
	max.f32 	%f51, %f51, %f38;
	add.s32 	%r12, %r23, %r1;
	setp.ge.u32 	%p6, %r12, %r15;
	@%p6 bra 	$L__BB4_11;

	mul.wide.u32 	%rd26, %r12, 4;
	add.s64 	%rd27, %rd2, %rd26;
	ld.f32 	%f39, [%rd27];
	max.f32 	%f51, %f51, %f39;

$L__BB4_11:
	add.s32 	%r23, %r23, %r5;
	setp.lt.u32 	%p7, %r23, %r15;
	@%p7 bra 	$L__BB4_9;

$L__BB4_12:
	shl.b32 	%r19, %r3, 2;
	mov.u32 	%r20, memory;
	add.s32 	%r14, %r20, %r19;
	st.shared.f32 	[%r14], %f51;
	bar.sync 	0;
	setp.lt.u32 	%p8, %r1, 1024;
	@%p8 bra 	$L__BB4_16;

	setp.gt.u32 	%p9, %r3, 511;
	@%p9 bra 	$L__BB4_15;

	ld.shared.f32 	%f40, [%r14+2048];
	max.f32 	%f51, %f51, %f40;
	st.shared.f32 	[%r14], %f51;

$L__BB4_15:
	bar.sync 	0;

$L__BB4_16:
	setp.lt.u32 	%p10, %r1, 512;
	@%p10 bra 	$L__BB4_20;

	setp.gt.u32 	%p11, %r3, 255;
	@%p11 bra 	$L__BB4_19;

	ld.shared.f32 	%f41, [%r14+1024];
	max.f32 	%f51, %f51, %f41;
	st.shared.f32 	[%r14], %f51;

$L__BB4_19:
	bar.sync 	0;

$L__BB4_20:
	setp.lt.u32 	%p12, %r1, 256;
	@%p12 bra 	$L__BB4_24;

	setp.gt.u32 	%p13, %r3, 127;
	@%p13 bra 	$L__BB4_23;

	ld.shared.f32 	%f42, [%r14+512];
	max.f32 	%f51, %f51, %f42;
	st.shared.f32 	[%r14], %f51;

$L__BB4_23:
	bar.sync 	0;

$L__BB4_24:
	setp.lt.u32 	%p14, %r1, 128;
	@%p14 bra 	$L__BB4_28;

	setp.gt.u32 	%p15, %r3, 63;
	@%p15 bra 	$L__BB4_27;

	ld.shared.f32 	%f43, [%r14+256];
	max.f32 	%f51, %f51, %f43;
	st.shared.f32 	[%r14], %f51;

$L__BB4_27:
	bar.sync 	0;

$L__BB4_28:
	setp.gt.u32 	%p16, %r3, 31;
	@%p16 bra 	$L__BB4_41;

	setp.lt.u32 	%p17, %r1, 64;
	@%p17 bra 	$L__BB4_31;

	ld.volatile.shared.f32 	%f44, [%r14+128];
	max.f32 	%f51, %f51, %f44;
	st.volatile.shared.f32 	[%r14], %f51;

$L__BB4_31:
	setp.lt.u32 	%p18, %r1, 32;
	@%p18 bra 	$L__BB4_33;

	ld.volatile.shared.f32 	%f45, [%r14+64];
	max.f32 	%f51, %f51, %f45;
	st.volatile.shared.f32 	[%r14], %f51;

$L__BB4_33:
	setp.lt.u32 	%p19, %r1, 16;
	@%p19 bra 	$L__BB4_35;

	ld.volatile.shared.f32 	%f46, [%r14+32];
	max.f32 	%f51, %f51, %f46;
	st.volatile.shared.f32 	[%r14], %f51;

$L__BB4_35:
	setp.lt.u32 	%p20, %r1, 8;
	@%p20 bra 	$L__BB4_37;

	ld.volatile.shared.f32 	%f47, [%r14+16];
	max.f32 	%f51, %f51, %f47;
	st.volatile.shared.f32 	[%r14], %f51;

$L__BB4_37:
	setp.lt.u32 	%p21, %r1, 4;
	@%p21 bra 	$L__BB4_39;

	ld.volatile.shared.f32 	%f48, [%r14+8];
	max.f32 	%f51, %f51, %f48;
	st.volatile.shared.f32 	[%r14], %f51;

$L__BB4_39:
	setp.lt.u32 	%p22, %r1, 2;
	@%p22 bra 	$L__BB4_41;

	ld.volatile.shared.f32 	%f49, [%r14+4];
	max.f32 	%f50, %f51, %f49;
	st.volatile.shared.f32 	[%r14], %f50;

$L__BB4_41:
	setp.ne.s32 	%p23, %r3, 0;
	@%p23 bra 	$L__BB4_46;

	ld.shared.f32 	%f32, [memory];
	cvta.to.global.u64 	%rd28, %rd13;
	add.s64 	%rd8, %rd28, 16;
	ld.global.u64 	%rd29, [%rd28+16];
	setp.eq.s64 	%p24, %rd29, 0;
	@%p24 bra 	$L__BB4_44;

	add.u64 	%rd30, %SP, 0;
	add.u64 	%rd31, %SPL, 0;
	mov.u32 	%r21, 0;
	st.local.v2.u32 	[%rd31], {%r21, %r2};
	mov.u64 	%rd32, $str;
	cvta.global.u64 	%rd33, %rd32;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd33;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd30;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r22, [retval0+0];
	} // callseq 2
	// begin inline asm
	trap;
	// end inline asm
	ld.global.u64 	%rd41, [%rd8+16];
	bra.uni 	$L__BB4_45;

$L__BB4_44:
	ld.global.u64 	%rd34, [%rd8+16];
	mul.wide.u32 	%rd35, %r2, 4;
	add.s64 	%rd41, %rd34, %rd35;

$L__BB4_45:
	st.f32 	[%rd41], %f32;

$L__BB4_46:
	ret;

}
	// .globl	reduce_max_d
.visible .entry reduce_max_d(
	.param .u64 reduce_max_d_param_0,
	.param .u64 reduce_max_d_param_1,
	.param .u32 reduce_max_d_param_2
)
{
	.local .align 8 .b8 	__local_depot5[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<25>;
	.reg .b32 	%r<26>;
	.reg .f64 	%fd<69>;
	.reg .b64 	%rd<42>;


	mov.u64 	%SPL, __local_depot5;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd12, [reduce_max_d_param_0];
	ld.param.u64 	%rd13, [reduce_max_d_param_1];
	ld.param.u32 	%r15, [reduce_max_d_param_2];
	mov.u32 	%r1, %ntid.x;
	shl.b32 	%r16, %r1, 1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	mad.lo.s32 	%r23, %r16, %r2, %r3;
	mov.u32 	%r17, %nctaid.x;
	mul.lo.s32 	%r5, %r16, %r17;
	setp.ge.u32 	%p1, %r23, %r15;
	mov.f64 	%fd51, 0dFFF0000000000000;
	@%p1 bra 	$L__BB5_12;

	cvta.to.global.u64 	%rd14, %rd12;
	ld.global.u64 	%rd1, [%rd14+16];
	setp.eq.s64 	%p2, %rd1, 0;
	ld.global.u64 	%rd2, [%rd14+32];
	@%p2 bra 	$L__BB5_9;

	mov.u64 	%rd39, %rd1;

$L__BB5_3:
	mul.wide.u32 	%rd15, %r23, 4;
	add.s64 	%rd16, %rd39, %rd15;
	ld.u32 	%r18, [%rd16];
	mul.wide.u32 	%rd17, %r18, 8;
	add.s64 	%rd18, %rd2, %rd17;
	ld.f64 	%fd35, [%rd18];
	max.f64 	%fd51, %fd51, %fd35;
	add.s32 	%r24, %r23, %r1;
	setp.ge.u32 	%p3, %r24, %r15;
	@%p3 bra 	$L__BB5_7;

	setp.eq.s64 	%p4, %rd39, 0;
	mov.u64 	%rd39, 0;
	@%p4 bra 	$L__BB5_6;

	mul.wide.u32 	%rd20, %r24, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.u32 	%r24, [%rd21];
	mov.u64 	%rd39, %rd1;

$L__BB5_6:
	mul.wide.u32 	%rd22, %r24, 8;
	add.s64 	%rd23, %rd2, %rd22;
	ld.f64 	%fd36, [%rd23];
	max.f64 	%fd51, %fd51, %fd36;

$L__BB5_7:
	add.s32 	%r23, %r23, %r5;
	setp.lt.u32 	%p5, %r23, %r15;
	@%p5 bra 	$L__BB5_3;
	bra.uni 	$L__BB5_12;

$L__BB5_9:
	mul.wide.u32 	%rd24, %r23, 8;
	add.s64 	%rd25, %rd2, %rd24;
	ld.f64 	%fd38, [%rd25];
	max.f64 	%fd51, %fd51, %fd38;
	add.s32 	%r12, %r23, %r1;
	setp.ge.u32 	%p6, %r12, %r15;
	@%p6 bra 	$L__BB5_11;

	mul.wide.u32 	%rd26, %r12, 8;
	add.s64 	%rd27, %rd2, %rd26;
	ld.f64 	%fd39, [%rd27];
	max.f64 	%fd51, %fd51, %fd39;

$L__BB5_11:
	add.s32 	%r23, %r23, %r5;
	setp.lt.u32 	%p7, %r23, %r15;
	@%p7 bra 	$L__BB5_9;

$L__BB5_12:
	shl.b32 	%r19, %r3, 3;
	mov.u32 	%r20, memory;
	add.s32 	%r14, %r20, %r19;
	st.shared.f64 	[%r14], %fd51;
	bar.sync 	0;
	setp.lt.u32 	%p8, %r1, 1024;
	@%p8 bra 	$L__BB5_16;

	setp.gt.u32 	%p9, %r3, 511;
	@%p9 bra 	$L__BB5_15;

	ld.shared.f64 	%fd40, [%r14+4096];
	max.f64 	%fd51, %fd51, %fd40;
	st.shared.f64 	[%r14], %fd51;

$L__BB5_15:
	bar.sync 	0;

$L__BB5_16:
	setp.lt.u32 	%p10, %r1, 512;
	@%p10 bra 	$L__BB5_20;

	setp.gt.u32 	%p11, %r3, 255;
	@%p11 bra 	$L__BB5_19;

	ld.shared.f64 	%fd41, [%r14+2048];
	max.f64 	%fd51, %fd51, %fd41;
	st.shared.f64 	[%r14], %fd51;

$L__BB5_19:
	bar.sync 	0;

$L__BB5_20:
	setp.lt.u32 	%p12, %r1, 256;
	@%p12 bra 	$L__BB5_24;

	setp.gt.u32 	%p13, %r3, 127;
	@%p13 bra 	$L__BB5_23;

	ld.shared.f64 	%fd42, [%r14+1024];
	max.f64 	%fd51, %fd51, %fd42;
	st.shared.f64 	[%r14], %fd51;

$L__BB5_23:
	bar.sync 	0;

$L__BB5_24:
	setp.lt.u32 	%p14, %r1, 128;
	@%p14 bra 	$L__BB5_28;

	setp.gt.u32 	%p15, %r3, 63;
	@%p15 bra 	$L__BB5_27;

	ld.shared.f64 	%fd43, [%r14+512];
	max.f64 	%fd51, %fd51, %fd43;
	st.shared.f64 	[%r14], %fd51;

$L__BB5_27:
	bar.sync 	0;

$L__BB5_28:
	setp.gt.u32 	%p16, %r3, 31;
	@%p16 bra 	$L__BB5_41;

	setp.lt.u32 	%p17, %r1, 64;
	@%p17 bra 	$L__BB5_31;

	ld.volatile.shared.f64 	%fd44, [%r14+256];
	max.f64 	%fd51, %fd51, %fd44;
	st.volatile.shared.f64 	[%r14], %fd51;

$L__BB5_31:
	setp.lt.u32 	%p18, %r1, 32;
	@%p18 bra 	$L__BB5_33;

	ld.volatile.shared.f64 	%fd45, [%r14+128];
	max.f64 	%fd51, %fd51, %fd45;
	st.volatile.shared.f64 	[%r14], %fd51;

$L__BB5_33:
	setp.lt.u32 	%p19, %r1, 16;
	@%p19 bra 	$L__BB5_35;

	ld.volatile.shared.f64 	%fd46, [%r14+64];
	max.f64 	%fd51, %fd51, %fd46;
	st.volatile.shared.f64 	[%r14], %fd51;

$L__BB5_35:
	setp.lt.u32 	%p20, %r1, 8;
	@%p20 bra 	$L__BB5_37;

	ld.volatile.shared.f64 	%fd47, [%r14+32];
	max.f64 	%fd51, %fd51, %fd47;
	st.volatile.shared.f64 	[%r14], %fd51;

$L__BB5_37:
	setp.lt.u32 	%p21, %r1, 4;
	@%p21 bra 	$L__BB5_39;

	ld.volatile.shared.f64 	%fd48, [%r14+16];
	max.f64 	%fd51, %fd51, %fd48;
	st.volatile.shared.f64 	[%r14], %fd51;

$L__BB5_39:
	setp.lt.u32 	%p22, %r1, 2;
	@%p22 bra 	$L__BB5_41;

	ld.volatile.shared.f64 	%fd49, [%r14+8];
	max.f64 	%fd50, %fd51, %fd49;
	st.volatile.shared.f64 	[%r14], %fd50;

$L__BB5_41:
	setp.ne.s32 	%p23, %r3, 0;
	@%p23 bra 	$L__BB5_46;

	ld.shared.f64 	%fd32, [memory];
	cvta.to.global.u64 	%rd28, %rd13;
	add.s64 	%rd8, %rd28, 16;
	ld.global.u64 	%rd29, [%rd28+16];
	setp.eq.s64 	%p24, %rd29, 0;
	@%p24 bra 	$L__BB5_44;

	add.u64 	%rd30, %SP, 0;
	add.u64 	%rd31, %SPL, 0;
	mov.u32 	%r21, 0;
	st.local.v2.u32 	[%rd31], {%r21, %r2};
	mov.u64 	%rd32, $str;
	cvta.global.u64 	%rd33, %rd32;
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd33;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd30;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r22, [retval0+0];
	} // callseq 3
	// begin inline asm
	trap;
	// end inline asm
	ld.global.u64 	%rd41, [%rd8+16];
	bra.uni 	$L__BB5_45;

$L__BB5_44:
	ld.global.u64 	%rd34, [%rd8+16];
	mul.wide.u32 	%rd35, %r2, 8;
	add.s64 	%rd41, %rd34, %rd35;

$L__BB5_45:
	st.f64 	[%rd41], %fd32;

$L__BB5_46:
	ret;

}
	// .globl	reduce_min_f
.visible .entry reduce_min_f(
	.param .u64 reduce_min_f_param_0,
	.param .u64 reduce_min_f_param_1,
	.param .u32 reduce_min_f_param_2
)
{
	.local .align 8 .b8 	__local_depot6[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<25>;
	.reg .f32 	%f<69>;
	.reg .b32 	%r<26>;
	.reg .b64 	%rd<42>;


	mov.u64 	%SPL, __local_depot6;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd12, [reduce_min_f_param_0];
	ld.param.u64 	%rd13, [reduce_min_f_param_1];
	ld.param.u32 	%r15, [reduce_min_f_param_2];
	mov.u32 	%r1, %ntid.x;
	shl.b32 	%r16, %r1, 1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	mad.lo.s32 	%r23, %r16, %r2, %r3;
	mov.u32 	%r17, %nctaid.x;
	mul.lo.s32 	%r5, %r16, %r17;
	setp.ge.u32 	%p1, %r23, %r15;
	mov.f32 	%f51, 0f7F800000;
	@%p1 bra 	$L__BB6_12;

	cvta.to.global.u64 	%rd14, %rd12;
	ld.global.u64 	%rd1, [%rd14+16];
	setp.eq.s64 	%p2, %rd1, 0;
	ld.global.u64 	%rd2, [%rd14+32];
	@%p2 bra 	$L__BB6_9;

	mov.u64 	%rd39, %rd1;

$L__BB6_3:
	mul.wide.u32 	%rd15, %r23, 4;
	add.s64 	%rd16, %rd39, %rd15;
	ld.u32 	%r18, [%rd16];
	mul.wide.u32 	%rd17, %r18, 4;
	add.s64 	%rd18, %rd2, %rd17;
	ld.f32 	%f35, [%rd18];
	min.f32 	%f51, %f51, %f35;
	add.s32 	%r24, %r23, %r1;
	setp.ge.u32 	%p3, %r24, %r15;
	@%p3 bra 	$L__BB6_7;

	setp.eq.s64 	%p4, %rd39, 0;
	mov.u64 	%rd39, 0;
	@%p4 bra 	$L__BB6_6;

	mul.wide.u32 	%rd20, %r24, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.u32 	%r24, [%rd21];
	mov.u64 	%rd39, %rd1;

$L__BB6_6:
	mul.wide.u32 	%rd22, %r24, 4;
	add.s64 	%rd23, %rd2, %rd22;
	ld.f32 	%f36, [%rd23];
	min.f32 	%f51, %f51, %f36;

$L__BB6_7:
	add.s32 	%r23, %r23, %r5;
	setp.lt.u32 	%p5, %r23, %r15;
	@%p5 bra 	$L__BB6_3;
	bra.uni 	$L__BB6_12;

$L__BB6_9:
	mul.wide.u32 	%rd24, %r23, 4;
	add.s64 	%rd25, %rd2, %rd24;
	ld.f32 	%f38, [%rd25];
	min.f32 	%f51, %f51, %f38;
	add.s32 	%r12, %r23, %r1;
	setp.ge.u32 	%p6, %r12, %r15;
	@%p6 bra 	$L__BB6_11;

	mul.wide.u32 	%rd26, %r12, 4;
	add.s64 	%rd27, %rd2, %rd26;
	ld.f32 	%f39, [%rd27];
	min.f32 	%f51, %f51, %f39;

$L__BB6_11:
	add.s32 	%r23, %r23, %r5;
	setp.lt.u32 	%p7, %r23, %r15;
	@%p7 bra 	$L__BB6_9;

$L__BB6_12:
	shl.b32 	%r19, %r3, 2;
	mov.u32 	%r20, memory;
	add.s32 	%r14, %r20, %r19;
	st.shared.f32 	[%r14], %f51;
	bar.sync 	0;
	setp.lt.u32 	%p8, %r1, 1024;
	@%p8 bra 	$L__BB6_16;

	setp.gt.u32 	%p9, %r3, 511;
	@%p9 bra 	$L__BB6_15;

	ld.shared.f32 	%f40, [%r14+2048];
	min.f32 	%f51, %f51, %f40;
	st.shared.f32 	[%r14], %f51;

$L__BB6_15:
	bar.sync 	0;

$L__BB6_16:
	setp.lt.u32 	%p10, %r1, 512;
	@%p10 bra 	$L__BB6_20;

	setp.gt.u32 	%p11, %r3, 255;
	@%p11 bra 	$L__BB6_19;

	ld.shared.f32 	%f41, [%r14+1024];
	min.f32 	%f51, %f51, %f41;
	st.shared.f32 	[%r14], %f51;

$L__BB6_19:
	bar.sync 	0;

$L__BB6_20:
	setp.lt.u32 	%p12, %r1, 256;
	@%p12 bra 	$L__BB6_24;

	setp.gt.u32 	%p13, %r3, 127;
	@%p13 bra 	$L__BB6_23;

	ld.shared.f32 	%f42, [%r14+512];
	min.f32 	%f51, %f51, %f42;
	st.shared.f32 	[%r14], %f51;

$L__BB6_23:
	bar.sync 	0;

$L__BB6_24:
	setp.lt.u32 	%p14, %r1, 128;
	@%p14 bra 	$L__BB6_28;

	setp.gt.u32 	%p15, %r3, 63;
	@%p15 bra 	$L__BB6_27;

	ld.shared.f32 	%f43, [%r14+256];
	min.f32 	%f51, %f51, %f43;
	st.shared.f32 	[%r14], %f51;

$L__BB6_27:
	bar.sync 	0;

$L__BB6_28:
	setp.gt.u32 	%p16, %r3, 31;
	@%p16 bra 	$L__BB6_41;

	setp.lt.u32 	%p17, %r1, 64;
	@%p17 bra 	$L__BB6_31;

	ld.volatile.shared.f32 	%f44, [%r14+128];
	min.f32 	%f51, %f51, %f44;
	st.volatile.shared.f32 	[%r14], %f51;

$L__BB6_31:
	setp.lt.u32 	%p18, %r1, 32;
	@%p18 bra 	$L__BB6_33;

	ld.volatile.shared.f32 	%f45, [%r14+64];
	min.f32 	%f51, %f51, %f45;
	st.volatile.shared.f32 	[%r14], %f51;

$L__BB6_33:
	setp.lt.u32 	%p19, %r1, 16;
	@%p19 bra 	$L__BB6_35;

	ld.volatile.shared.f32 	%f46, [%r14+32];
	min.f32 	%f51, %f51, %f46;
	st.volatile.shared.f32 	[%r14], %f51;

$L__BB6_35:
	setp.lt.u32 	%p20, %r1, 8;
	@%p20 bra 	$L__BB6_37;

	ld.volatile.shared.f32 	%f47, [%r14+16];
	min.f32 	%f51, %f51, %f47;
	st.volatile.shared.f32 	[%r14], %f51;

$L__BB6_37:
	setp.lt.u32 	%p21, %r1, 4;
	@%p21 bra 	$L__BB6_39;

	ld.volatile.shared.f32 	%f48, [%r14+8];
	min.f32 	%f51, %f51, %f48;
	st.volatile.shared.f32 	[%r14], %f51;

$L__BB6_39:
	setp.lt.u32 	%p22, %r1, 2;
	@%p22 bra 	$L__BB6_41;

	ld.volatile.shared.f32 	%f49, [%r14+4];
	min.f32 	%f50, %f51, %f49;
	st.volatile.shared.f32 	[%r14], %f50;

$L__BB6_41:
	setp.ne.s32 	%p23, %r3, 0;
	@%p23 bra 	$L__BB6_46;

	ld.shared.f32 	%f32, [memory];
	cvta.to.global.u64 	%rd28, %rd13;
	add.s64 	%rd8, %rd28, 16;
	ld.global.u64 	%rd29, [%rd28+16];
	setp.eq.s64 	%p24, %rd29, 0;
	@%p24 bra 	$L__BB6_44;

	add.u64 	%rd30, %SP, 0;
	add.u64 	%rd31, %SPL, 0;
	mov.u32 	%r21, 0;
	st.local.v2.u32 	[%rd31], {%r21, %r2};
	mov.u64 	%rd32, $str;
	cvta.global.u64 	%rd33, %rd32;
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd33;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd30;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r22, [retval0+0];
	} // callseq 4
	// begin inline asm
	trap;
	// end inline asm
	ld.global.u64 	%rd41, [%rd8+16];
	bra.uni 	$L__BB6_45;

$L__BB6_44:
	ld.global.u64 	%rd34, [%rd8+16];
	mul.wide.u32 	%rd35, %r2, 4;
	add.s64 	%rd41, %rd34, %rd35;

$L__BB6_45:
	st.f32 	[%rd41], %f32;

$L__BB6_46:
	ret;

}
	// .globl	reduce_min_d
.visible .entry reduce_min_d(
	.param .u64 reduce_min_d_param_0,
	.param .u64 reduce_min_d_param_1,
	.param .u32 reduce_min_d_param_2
)
{
	.local .align 8 .b8 	__local_depot7[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<25>;
	.reg .b32 	%r<26>;
	.reg .f64 	%fd<69>;
	.reg .b64 	%rd<42>;


	mov.u64 	%SPL, __local_depot7;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd12, [reduce_min_d_param_0];
	ld.param.u64 	%rd13, [reduce_min_d_param_1];
	ld.param.u32 	%r15, [reduce_min_d_param_2];
	mov.u32 	%r1, %ntid.x;
	shl.b32 	%r16, %r1, 1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	mad.lo.s32 	%r23, %r16, %r2, %r3;
	mov.u32 	%r17, %nctaid.x;
	mul.lo.s32 	%r5, %r16, %r17;
	setp.ge.u32 	%p1, %r23, %r15;
	mov.f64 	%fd51, 0d7FF0000000000000;
	@%p1 bra 	$L__BB7_12;

	cvta.to.global.u64 	%rd14, %rd12;
	ld.global.u64 	%rd1, [%rd14+16];
	setp.eq.s64 	%p2, %rd1, 0;
	ld.global.u64 	%rd2, [%rd14+32];
	@%p2 bra 	$L__BB7_9;

	mov.u64 	%rd39, %rd1;

$L__BB7_3:
	mul.wide.u32 	%rd15, %r23, 4;
	add.s64 	%rd16, %rd39, %rd15;
	ld.u32 	%r18, [%rd16];
	mul.wide.u32 	%rd17, %r18, 8;
	add.s64 	%rd18, %rd2, %rd17;
	ld.f64 	%fd35, [%rd18];
	min.f64 	%fd51, %fd51, %fd35;
	add.s32 	%r24, %r23, %r1;
	setp.ge.u32 	%p3, %r24, %r15;
	@%p3 bra 	$L__BB7_7;

	setp.eq.s64 	%p4, %rd39, 0;
	mov.u64 	%rd39, 0;
	@%p4 bra 	$L__BB7_6;

	mul.wide.u32 	%rd20, %r24, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.u32 	%r24, [%rd21];
	mov.u64 	%rd39, %rd1;

$L__BB7_6:
	mul.wide.u32 	%rd22, %r24, 8;
	add.s64 	%rd23, %rd2, %rd22;
	ld.f64 	%fd36, [%rd23];
	min.f64 	%fd51, %fd51, %fd36;

$L__BB7_7:
	add.s32 	%r23, %r23, %r5;
	setp.lt.u32 	%p5, %r23, %r15;
	@%p5 bra 	$L__BB7_3;
	bra.uni 	$L__BB7_12;

$L__BB7_9:
	mul.wide.u32 	%rd24, %r23, 8;
	add.s64 	%rd25, %rd2, %rd24;
	ld.f64 	%fd38, [%rd25];
	min.f64 	%fd51, %fd51, %fd38;
	add.s32 	%r12, %r23, %r1;
	setp.ge.u32 	%p6, %r12, %r15;
	@%p6 bra 	$L__BB7_11;

	mul.wide.u32 	%rd26, %r12, 8;
	add.s64 	%rd27, %rd2, %rd26;
	ld.f64 	%fd39, [%rd27];
	min.f64 	%fd51, %fd51, %fd39;

$L__BB7_11:
	add.s32 	%r23, %r23, %r5;
	setp.lt.u32 	%p7, %r23, %r15;
	@%p7 bra 	$L__BB7_9;

$L__BB7_12:
	shl.b32 	%r19, %r3, 3;
	mov.u32 	%r20, memory;
	add.s32 	%r14, %r20, %r19;
	st.shared.f64 	[%r14], %fd51;
	bar.sync 	0;
	setp.lt.u32 	%p8, %r1, 1024;
	@%p8 bra 	$L__BB7_16;

	setp.gt.u32 	%p9, %r3, 511;
	@%p9 bra 	$L__BB7_15;

	ld.shared.f64 	%fd40, [%r14+4096];
	min.f64 	%fd51, %fd51, %fd40;
	st.shared.f64 	[%r14], %fd51;

$L__BB7_15:
	bar.sync 	0;

$L__BB7_16:
	setp.lt.u32 	%p10, %r1, 512;
	@%p10 bra 	$L__BB7_20;

	setp.gt.u32 	%p11, %r3, 255;
	@%p11 bra 	$L__BB7_19;

	ld.shared.f64 	%fd41, [%r14+2048];
	min.f64 	%fd51, %fd51, %fd41;
	st.shared.f64 	[%r14], %fd51;

$L__BB7_19:
	bar.sync 	0;

$L__BB7_20:
	setp.lt.u32 	%p12, %r1, 256;
	@%p12 bra 	$L__BB7_24;

	setp.gt.u32 	%p13, %r3, 127;
	@%p13 bra 	$L__BB7_23;

	ld.shared.f64 	%fd42, [%r14+1024];
	min.f64 	%fd51, %fd51, %fd42;
	st.shared.f64 	[%r14], %fd51;

$L__BB7_23:
	bar.sync 	0;

$L__BB7_24:
	setp.lt.u32 	%p14, %r1, 128;
	@%p14 bra 	$L__BB7_28;

	setp.gt.u32 	%p15, %r3, 63;
	@%p15 bra 	$L__BB7_27;

	ld.shared.f64 	%fd43, [%r14+512];
	min.f64 	%fd51, %fd51, %fd43;
	st.shared.f64 	[%r14], %fd51;

$L__BB7_27:
	bar.sync 	0;

$L__BB7_28:
	setp.gt.u32 	%p16, %r3, 31;
	@%p16 bra 	$L__BB7_41;

	setp.lt.u32 	%p17, %r1, 64;
	@%p17 bra 	$L__BB7_31;

	ld.volatile.shared.f64 	%fd44, [%r14+256];
	min.f64 	%fd51, %fd51, %fd44;
	st.volatile.shared.f64 	[%r14], %fd51;

$L__BB7_31:
	setp.lt.u32 	%p18, %r1, 32;
	@%p18 bra 	$L__BB7_33;

	ld.volatile.shared.f64 	%fd45, [%r14+128];
	min.f64 	%fd51, %fd51, %fd45;
	st.volatile.shared.f64 	[%r14], %fd51;

$L__BB7_33:
	setp.lt.u32 	%p19, %r1, 16;
	@%p19 bra 	$L__BB7_35;

	ld.volatile.shared.f64 	%fd46, [%r14+64];
	min.f64 	%fd51, %fd51, %fd46;
	st.volatile.shared.f64 	[%r14], %fd51;

$L__BB7_35:
	setp.lt.u32 	%p20, %r1, 8;
	@%p20 bra 	$L__BB7_37;

	ld.volatile.shared.f64 	%fd47, [%r14+32];
	min.f64 	%fd51, %fd51, %fd47;
	st.volatile.shared.f64 	[%r14], %fd51;

$L__BB7_37:
	setp.lt.u32 	%p21, %r1, 4;
	@%p21 bra 	$L__BB7_39;

	ld.volatile.shared.f64 	%fd48, [%r14+16];
	min.f64 	%fd51, %fd51, %fd48;
	st.volatile.shared.f64 	[%r14], %fd51;

$L__BB7_39:
	setp.lt.u32 	%p22, %r1, 2;
	@%p22 bra 	$L__BB7_41;

	ld.volatile.shared.f64 	%fd49, [%r14+8];
	min.f64 	%fd50, %fd51, %fd49;
	st.volatile.shared.f64 	[%r14], %fd50;

$L__BB7_41:
	setp.ne.s32 	%p23, %r3, 0;
	@%p23 bra 	$L__BB7_46;

	ld.shared.f64 	%fd32, [memory];
	cvta.to.global.u64 	%rd28, %rd13;
	add.s64 	%rd8, %rd28, 16;
	ld.global.u64 	%rd29, [%rd28+16];
	setp.eq.s64 	%p24, %rd29, 0;
	@%p24 bra 	$L__BB7_44;

	add.u64 	%rd30, %SP, 0;
	add.u64 	%rd31, %SPL, 0;
	mov.u32 	%r21, 0;
	st.local.v2.u32 	[%rd31], {%r21, %r2};
	mov.u64 	%rd32, $str;
	cvta.global.u64 	%rd33, %rd32;
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd33;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd30;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r22, [retval0+0];
	} // callseq 5
	// begin inline asm
	trap;
	// end inline asm
	ld.global.u64 	%rd41, [%rd8+16];
	bra.uni 	$L__BB7_45;

$L__BB7_44:
	ld.global.u64 	%rd34, [%rd8+16];
	mul.wide.u32 	%rd35, %r2, 8;
	add.s64 	%rd41, %rd34, %rd35;

$L__BB7_45:
	st.f64 	[%rd41], %fd32;

$L__BB7_46:
	ret;

}

