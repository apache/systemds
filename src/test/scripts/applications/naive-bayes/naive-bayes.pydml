#-------------------------------------------------------------
#
# (C) Copyright IBM Corp. 2010, 2015
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
#-------------------------------------------------------------

# Implements multinomial naive Bayes classifier with Laplace correction
#
# Example Usage:
# hadoop jar SystemML.jar -f naive-bayes.pydml -python -nvargs X=<Data> Y=<labels> classes=<Num Classes> laplace=<Laplace Correction> prior=<Model file1> conditionals=<Model file2> accuracy=<accuracy file> fmt="text"
#

# defaults
# $laplace = 1
fmt = ifdef($fmt, "text")

# reading input args
numClasses = $classes
D = load($X)
C = load($Y)
laplace_correction = ifdef($laplace, 1)

numRows = nrow(D)
numFeatures = ncol(D)

# Compute conditionals

# Compute the feature counts for each class
classFeatureCounts = full(0, rows=numClasses, cols=numFeatures)
parfor (i in 1:numFeatures):
  Col = D[,i]
  classFeatureCounts[,i] = aggregate(target=Col, groups=C, fn="sum", ngroups=numClasses)

# Compute the total feature count for each class 
# and add the number of features to this sum
# for subsequent regularization (Laplace's rule)
classSums = rowSums(classFeatureCounts) + numFeatures*laplace_correction

# Compute class conditional probabilities
ones = full(1, rows=1, cols=numFeatures)
repClassSums = dot(classSums, ones)
class_conditionals = (classFeatureCounts + laplace_correction) / repClassSums

# Compute class priors
class_counts = aggregate(target=C, groups=C, fn="count", ngroups=numClasses)
class_prior = class_counts / numRows

# Compute accuracy on training set
ones = full(1, rows=numRows, cols=1)
D_w_ones = append(D, ones)
model = append(class_conditionals, class_prior)
log_model = log(model)
transpose_log_model = log_model.transpose()
log_probs = dot(D_w_ones, transpose_log_model)
pred = rowIndexMax(log_probs)
acc = sum(ppred(pred, C, "==")) / numRows * 100

acc_str = "Training Accuracy (%): " + acc
print(acc_str)
save(acc_str, $accuracy)

# write out the model
save(class_prior, $prior, format=fmt)
save(class_conditionals, $conditionals, format=fmt)
  