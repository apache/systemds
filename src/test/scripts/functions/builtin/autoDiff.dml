#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
#-------------------------------------------------------------

source("nn/layers/affine.dml") as affine

# # # initializing the matrix by hand parsing issues in rand command within lineage
X_batch = matrix("1 2 3 4
                  1 2 3 4
                  1 2 3 4
                  1 2 3 4", rows=4, cols=4)
                  
W_1 = matrix("1.1 0.2 0.3 0.24
                  1.1 0.2 0.3 0.24
                  1.1 0.2 0.3 0.24
                  1.1 0.2 0.3 0.24", rows=4, cols=4)
b_1 = matrix(0, rows=1, cols=4)

prob = affine::forward(X_batch, W_1, b_1)
lin = lineage(prob)

# print("lineage of forward: "+lin)


# # # compute the derivatives from the autoDiff
diffs = autoDiff(name="affine",X=X_batch, dout=prob, W=list(W_1), B=list(b_1), lineage=lin);


ad_dX = as.matrix(diffs['dX'])
ad_dW = as.matrix(diffs['dW'])
ad_dB = as.matrix(diffs['dB'])

# # # compute the derivatives from the backward script
[dX, dW, dB] = affine::backward(prob, X_batch, W_1, b_1)


sameX = dX != ad_dX
sameW = dW != ad_dW
sameB = dB != ad_dB

output = ((sum(sameX) == 0) & (sum(sameW) == 0) & (sum(sameB) == 0))

write(dX, $1)
write(ad_dX, $2)
