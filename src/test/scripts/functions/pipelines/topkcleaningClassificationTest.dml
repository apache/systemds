#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
#-------------------------------------------------------------
# Generate the logical pipelines for data cleaning

source("scripts/pipelines/scripts/utils.dml") as utils;

# read the inputs
F = read($dirtyData, data_type="frame", format="csv", header=TRUE, 
  naStrings= ["NA", "null","  ","NaN", "nan", "", "?", "99999"]);

metaInfo = read($metaData, data_type="frame", format="csv", header=FALSE);
primitives = read($primitives, data_type = "frame", format="csv", header= TRUE)
param = read($parameters, data_type = "frame", format="csv", header= TRUE)
topK = $topk
resources = $rv
sample=$sample
output=$output
testCV = as.logical($testCV)
cvk = as.integer($cvk)
trainTestSplit = as.double($split)
evalFunc = "evalClassification"
split = nrow(F) * trainTestSplit
if(testCV) {

  trainData = F
  testData = as.frame("0")
}
else {

  trainData = F[1:split,]
  testData = F[split+1:nrow(F),]
}

if(nrow(metaInfo) < 2)
  stop("incomplete meta info")

metaInfo = metaInfo[, 2:ncol(metaInfo)]
# # # split in train/test 70/30

# [topKPipelines, topKHyperParams, topKScores, bestLogical, features, dirtyScore, evalHp] = 
result = topk_cleaning(dataTrain=trainData, dataTest=testData, metaData=metaInfo, primitives=primitives, parameters=param,
  cmr=matrix("2 0.7 1", rows=1, cols=3), evaluationFunc=evalFunc, evalFunHp=as.matrix(0),
  topK=topK, resource_val=resources, cv=testCV, cvk=cvk, sample=sample, isLastLabel=TRUE, correctTypos=FALSE, output=output) 

write(result, $O)


# UDF for evaluation  
# choice of parameters provided by API, X, Y, clone_X, evalFunHp (hyper-param), trainML (boolean for optimizing hp internally or passed by externally )
evalClassification = function(Matrix[Double] X, Matrix[Double] Y, Matrix[Double] Xtest, Matrix[Double] Ytest, Matrix[Double] Xorig=as.matrix(0),
  Matrix[Double] evalFunHp, Integer trainML)
  
return(Matrix[Double] output)
{
  if(trainML == 1)
  {
    params = list("icpt", "reg", "tol", "maxii")
    paramRanges = list(seq(0, 2, 1), 10^seq(1,-3), 10^seq(1,-5), 10^seq(1,3));
    trainArgs = list(X=X, Y=Y, icpt=-1, reg=-1, tol=-1, maxi=100, maxii=-1, verbose=FALSE);
    [B1, opt] = utils::topk_gridSearch(X=X, y=Y, Xtest=Xtest, ytest=Ytest, train="multiLogReg", predict="accuracy", numB=ncol(X)+1, cv=FALSE, cvk=0,
      params=params, paramValues=paramRanges, trainArgs=trainArgs, verbose=FALSE);
    evalFunHp = as.matrix(opt)  
  }
  if(min(Y) == max(Y))
  {
    accuracy = as.matrix(0)
    a = 0
  }
  else {
    beta = multiLogReg(X=X, Y=Y, icpt=as.scalar(evalFunHp[1,1]), reg=as.scalar(evalFunHp[1,2]), tol=as.scalar(evalFunHp[1,3]), 
      maxi=as.scalar(evalFunHp[1,4]), maxii=50, verbose=FALSE);
    [prob, yhat, accuracy] = multiLogRegPredict(Xtest, beta, Ytest, FALSE)
    a = getAccuracy(Ytest, yhat, TRUE)
    print("accuracy: "+toString(accuracy)+" weighted accuracy: "+a)
    accuracy = as.matrix(accuracy)
  }
  output = cbind(accuracy, evalFunHp)
}

accuracy = function(Matrix[Double] X, Matrix[Double] y, Matrix[Double] B) return (Matrix[Double] err) {
  [M,yhat,acc] = multiLogRegPredict(X=X, B=B, Y=y, verbose=FALSE);
  err = as.matrix(1-(acc/100));
}