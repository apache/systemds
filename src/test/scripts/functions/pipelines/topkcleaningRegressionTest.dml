#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
#-------------------------------------------------------------
source("scripts/pipelines/scripts/utils.dml") as utils;

# read the inputs
F = read($dirtyData, data_type="frame", format="csv", header=TRUE, 
  naStrings= ["NA", "null","  ","NaN", "nan", "", "?", "99999"]);
# only for salaries data
F = F[, 2:ncol(F)]
# metaInfo = read($metaData, data_type="frame", format="csv", header=FALSE);
primitives = read($primitives, data_type = "frame", format="csv", header= TRUE)
param = read($parameters, data_type = "frame", format="csv", header= TRUE)
topK = $topk
resources = $rv
sample=$sample

[topKPipelines, topKHyperParams, topKScores, bestLogical, features, dirtyScore] = topk_cleaning(data=F,  primitives=primitives, parameters=param, 
  cmr=matrix("4 0.7 1", rows=1, cols=3), evaluationFunc="evalRegression", evalFunHp=as.matrix("0"), topK=topK, resource_val=resources, sample=sample, isLastLabel=TRUE)
  
     
print("dirty accuracy "+toString(dirtyScore))  
print("best logical pipelines "+toString(bestLogical))  
print("topk pipelines "+toString(topKPipelines))
print("topk hyper params "+toString(topKHyperParams))
print("topk  scores: \n"+toString(topKScores))
perf = as.scalar(topKScores[1, 1]) - dirtyScore
print("performce improvemnet "+ perf)
result = dirtyScore < as.scalar(topKScores[1, 1]) 
write(result, $O)



# UDF for evaluation  
# choice of parameters provided by API, X, Y, clone_X, evalFunHp (hyper-param), trainML (boolean for optimizing hp internally or passed by externally )
evalRegression = function(Matrix[Double] X, Matrix[Double] Y, Matrix[Double] Xorig, List[Unknown] metaList,
  Matrix[Double] evalFunHp, Integer trainML=0)
  
return(Matrix[Double] output)
{
  cv = 2
  mask = as.matrix(metaList['mask'])

  if(max(Y) == min(Y)) {
    print("Y contains only one class")
    accuracy = as.double(0)
  }
  else {
    if(trainML == 1)
    {
      # do the gridsearch for hyper-parameters
      params = list("icpt","reg", "tol", "maxi");
      paramRanges = list(seq(0,2),10^seq(0,-4), 10^seq(-6,-12), 10^seq(1,3));
      [B1, opt] = utils::topk_gridSearch(X=X, y=Y, train="lm", predict="wmape",
        numB=ncol(X)+1, cv=TRUE, params=params, paramValues=paramRanges);
      evalFunHp = as.matrix(opt)  
    }

    # do the k = 3 cross validations
    # evalFunHpM = as.matrix(evalFunHp)
    [accuracyMatrix] = crossV(X, Y, cv, evalFunHp)
    accuracyMatrix = removeEmpty(target=accuracyMatrix, margin="rows")
    score =  mean(accuracyMatrix)
    print(cv +" validation accuracy "+score)
  }
  output = cbind(as.matrix(score), evalFunHp)

}

wmape = function(Matrix[Double] X, Matrix[Double] y, Matrix[Double] B, Integer icpt) return (Matrix[Double] loss) {
  # loss = as.matrix(sum((y - X%*%B)^2));
  pred = lmPredict(X=X, B=B, ytest=y, icpt=icpt);
  WMAPE = sum(abs(y - pred))/sum(abs(y)) #this will give the lose into range of [0,1]
  loss = as.matrix(WMAPE) 
}



crossV = function(Matrix[Double] X, Matrix[Double] y, Integer k, Matrix[Double] hp) return (Matrix[Double] accuracyMatrix) 
{
  icpt = as.scalar(hp[1, 1])
  reg = as.scalar(hp[1, 2])
  tol = as.scalar(hp[1, 3])
  maxi = as.scalar(hp[1, 4])
  M = nrow(X);
  lim = floor(as.integer(M/k));
  accuracyMatrix = matrix(0, rows=k, cols=1)

	for (i in 1:k)
  {
    testS = ifelse(i==1, 1, ((i-1) * lim)+1)
    testE = i * lim;
    testSet = X[testS:testE,];
    testRes = y[testS:testE,];

    if (i == 1) {
      trainSet = X[testE+1:M,];
      trainRes = y[testE+1:M,];
    }
    else if(i == k)
    {
      trainSet = X[1:testS-1,];
      trainRes = y[1:testS-1,];
    }
    else {
      trainSet = rbind(X[1:testS-1,], X[testE+1:M,]);
      trainRes = rbind(y[1:testS-1,], y[testE+1:M,]);
    }
    beta = lm(X=trainSet, y=trainRes, icpt=icpt, reg=reg, tol=tol, maxi=maxi);
    acc = wmape(testSet, testRes, beta, icpt)
    accuracyMatrix[i] = (1 - acc)
  }
}
 