#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
#-------------------------------------------------------------

source("scripts/pipelines/scripts/utils.dml") as utils;

# read the inputs
F = read($dirtyData, data_type="frame", format="csv", header=TRUE,
  naStrings= ["NA", "null","  ","NaN", "nan", "", " ", "_nan_", "inf", "?", "NAN", "99999"]);
F = F[,2:ncol(F)]
primitives = read($primitives, data_type = "frame", format="csv", header= TRUE)
param = read($parameters, data_type = "frame", format="csv", header= TRUE)
topK = $topk
resources = $rv
sample=$sample
output=$output
testCV = as.logical($testCV)
trainTestSplit = as.double($split)
cvk = as.integer($cvk)

split = nrow(F) * trainTestSplit
  evalFunc = "evalRegression"
if(testCV) {
  trainData = F[1:split,]
  testData = frame("", rows=0, cols=0)
}
else {
  trainData = F[1:split,]
  testData = F[split+1:nrow(F),]
}

# # # split in train/test 70/30
#matrix("1 1e-6 1e-9 1000", rows=1, cols=4)
[topKPipelines, topKHyperParams, topKScores, baseLineScore, evalFunHp, applyFunc] = topk_cleaning(dataTrain=trainData, dataTest=testData,
  primitives=primitives, parameters=param, evaluationFunc=evalFunc, evalFunHp=as.matrix(NaN),
  topK=topK, resourceVal=resources, cv=testCV, cvk=cvk, sample=sample, isLastLabel=TRUE, correctTypos=FALSE)

write(topKPipelines, output+"/pip.csv", format="csv")
write(topKHyperParams, output+"/hp.csv", format="csv")
write(topKScores, output+"/bestAcc.csv", format="csv")
write(baseLineScore, output+"/dirtyScore.csv", format="csv")
write(evalFunHp, output+"/evalHp.csv", format="csv")
write(applyFunc, output+"/applyFunc.csv", format="csv")
result = baseLineScore < as.scalar(topKScores[1, 1])
write(result, $O)


# UDF for evaluation
# choice of parameters provided by API, X, Y, clone_X, evalFunHp (hyper-param), trainML (boolean for optimizing hp internally or passed by externally )
evalRegression = function(Matrix[Double] X, Matrix[Double] Y, Matrix[Double] Xtest, Matrix[Double] Ytest, Matrix[Double] Xorig=as.matrix(0),
  Matrix[Double] evalFunHp)
return(Matrix[Double] output)
{
  if(is.na(as.scalar(evalFunHp[1,1])))
  {
    # do the gridsearch for hyper-parameters
    lArgs=list(X=X, y=Y, intercept=0, reg=-1, tol=-1, maxIter=-1, verbose=FALSE);
    params = list("intercept","reg", "tol");
    paramRanges = list(seq(0,2,1), 10^seq(0,-4), 10^seq(-6,-12));
    [B1, opt] = gridSearch(X=X, y=Y, train="lm", predict="wmape", trainArgs=lArgs,
      numB=ncol(X)+1, params=params, paramValues=paramRanges, cv=TRUE, cvk=3, verbose=FALSE);
    evalFunHp = as.matrix(opt)
  }
  beta = lm(X=X, y=Y, intercept=as.scalar(evalFunHp[1,1]), reg=as.scalar(evalFunHp[1,2]),
    tol=as.scalar(evalFunHp[1,3]), maxIter=1000, verbose=FALSE);

  acc = wmape(Xtest, Ytest, beta)
  accuracy = (1 - acc)
  output = cbind(accuracy, evalFunHp)
}

# wmape = function(Matrix[Double] X, Matrix[Double] y, Matrix[Double] B) return (Matrix[Double] loss) {
  # # loss = as.matrix(sum((y - X%*%B)^2));
  # pred = lmPredict(X=X, B=B, Ytest=y);
  # WMAPE = sum(abs(y - pred))/sum(abs(y)) #this will give the lose into range of [0,1]
  # loss = ifelse(is.na(as.matrix(WMAPE)), as.matrix(0), as.matrix(WMAPE))
# }

wmape = function(Matrix[Double] X, Matrix[Double] y, Matrix[Double] B) return (Matrix[Double] loss) {
  # loss = as.matrix(sum((y - X%*%B)^2));
  pred = lmPredict(X=X, B=B, Ytest=y, verbose=FALSE);
  # print("WMAPO: "+(1 - (sum(abs((pred - y)/(pred + y)))/nrow(y))))
  WMAPE = 1 - (sum(abs((pred - y)/(pred + y)))/nrow(y)) #this will give the lose into range of [0,1]
  loss = ifelse(is.na(as.matrix(WMAPE)), as.matrix(0), as.matrix(WMAPE))
}
