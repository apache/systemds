#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
#-------------------------------------------------------------

source("src/test/scripts/applications/nn/component/efficientNet.dml") as eff

# Read training data
data = read($1, format="csv")

N = nrow(data)

# Extract images and labels
images = data[,2:ncol(data)]
labels = data[,1]

# Scale images to [0,1], and one-hot encode the labels
images = images / 255.0
labels = table(seq(1, N), labels+1, N, 10)

# Load the trained model
model = read("output/model.txt", format="text")

# Generate random data for predicting
num_test_images = as.integer($3)
test_images = rand(rows=num_test_images, cols=28*28, min=0, max=1, sparsity=1.0, pdf="uniform", seed=42)
test_labels = rand(rows=num_test_images, cols=1, min=0, max=9, sparsity=1.0, pdf="uniform", seed=42)
test_labels = round(test_labels)

# One-hot encode the test labels
test_labels = table(seq(1, num_test_images), test_labels+1, num_test_images, 10)

# Materialize intermediates by computing and printing their sums
print("Sum of test_images: " + sum(test_images))
print("Sum of test_labels: " + sum(test_labels))

# Also Predict in Batches since otherwise we can run into Memory Issues
# Could be unnecessary on more powerful machines :)
batch_size = 1024  # Adjust the batch size to a larger value
iters = ceil(num_test_images / batch_size)
partial_accuracies = matrix(0, rows=iters, cols=1)

# Start timing the parfor loop
parfor_start_time = time()
parfor(i in 1:iters) {
  beg = ((i-1) * batch_size) %% num_test_images + 1
  end = min(num_test_images, beg + batch_size - 1)
  X_batch = test_images[beg:end,]
  y_batch = test_labels[beg:end,]

  pred = eff::netPredict(X_batch, model, 1, 28, 28)
  partial_accuracies[i,1] = mean(rowIndexMax(pred) == rowIndexMax(y_batch))
}
# End timing the parfor loop
parfor_end_time = time()
parfor_execution_time = floor((parfor_end_time-parfor_start_time)/1000000000)
print("Parfor Execution Time: " + parfor_execution_time)
